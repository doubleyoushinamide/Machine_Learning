{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a256bc4e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-29T01:15:46.273792Z",
     "iopub.status.busy": "2025-07-29T01:15:46.273556Z",
     "iopub.status.idle": "2025-07-29T01:17:08.746422Z",
     "shell.execute_reply": "2025-07-29T01:17:08.745514Z"
    },
    "papermill": {
     "duration": 82.477424,
     "end_time": "2025-07-29T01:17:08.748180",
     "exception": false,
     "start_time": "2025-07-29T01:15:46.270756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q torch torchvision opencv-python numpy Pillow matplotlib albumentations tqdm  scikit-learn tensorboard optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e012a80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T01:17:08.812426Z",
     "iopub.status.busy": "2025-07-29T01:17:08.811896Z",
     "iopub.status.idle": "2025-07-29T01:17:08.819187Z",
     "shell.execute_reply": "2025-07-29T01:17:08.818650Z"
    },
    "papermill": {
     "duration": 0.040351,
     "end_time": "2025-07-29T01:17:08.820274",
     "exception": false,
     "start_time": "2025-07-29T01:17:08.779923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Configuration file for Facial Detection System\n",
    "Optimized for Kaggle hardware constraints\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "class Config:\n",
    "    # Hardware constraints for Kaggle\n",
    "    GPU_MEMORY_LIMIT = 14  # GB (leaving 2GB buffer)\n",
    "    RAM_LIMIT = 28  # GB (leaving 4GB buffer)\n",
    "    CPU_CORES = 4\n",
    "    \n",
    "    # Dataset settings\n",
    "    DATASET_NAME = \"davido-recognition\"  # Custom Davido recognition dataset\n",
    "    TRAIN_SPLIT = 0.8\n",
    "    VAL_SPLIT = 0.2\n",
    "    IMAGE_SIZE = (160, 160)  # Standard for face recognition models (e.g., FaceNet)\n",
    "    BATCH_SIZE = 16  # Optimized for P100 GPU memory\n",
    "    DAVIDO_LABEL = \"Davido\"\n",
    "    UNKNOWN_LABEL = \"Unknown\"\n",
    "    CLASS_NAMES = [DAVIDO_LABEL, UNKNOWN_LABEL]\n",
    "    NUM_CLASSES = 2\n",
    "    \n",
    "    # Data augmentation settings\n",
    "    AUGMENTATION_PROBABILITY = 0.8\n",
    "    ROTATION_RANGE = 15\n",
    "    BRIGHTNESS_RANGE = 0.2\n",
    "    CONTRAST_RANGE = 0.2\n",
    "    HORIZONTAL_FLIP_PROB = 0.5\n",
    "    VERTICAL_FLIP_PROB = 0.0  # Keep faces upright\n",
    "    \n",
    "    # Model settings\n",
    "    MODEL_TYPE = \"mobilenet_v2\"  # Lightweight and efficient for classification\n",
    "    PRETRAINED = True\n",
    "    CONFIDENCE_THRESHOLD = 0.8  # Higher threshold to reduce false positives\n",
    "    NMS_THRESHOLD = 0.4\n",
    "    \n",
    "    # Training settings (optimized for larger dataset)\n",
    "    EPOCHS = 100  # More epochs for larger dataset\n",
    "    LEARNING_RATE = 0.001\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    SCHEDULER_STEP_SIZE = 15\n",
    "    SCHEDULER_GAMMA = 0.5\n",
    "    \n",
    "    # Early stopping settings (adjusted for larger dataset)\n",
    "    EARLY_STOPPING_PATIENCE = 15  # More patience for larger dataset\n",
    "    EARLY_STOPPING_MIN_DELTA = 0.0005  # Smaller improvement threshold\n",
    "    \n",
    "    # Real-time detection settings\n",
    "    FPS_TARGET = 15  # Process every 4th frame at 60fps\n",
    "    FRAME_SKIP = 4\n",
    "    DETECTION_INTERVAL = 3  # frames between detections\n",
    "    \n",
    "    # Paths (Updated for Kaggle)\n",
    "    DATA_DIR = \"/kaggle/input/input-data\"  # Kaggle data directory\n",
    "    SCREENSHOT_DIR = \"./output/screenshots\"\n",
    "    MODELS_DIR = \"./models\"\n",
    "    LOGS_DIR = \"./logs\"\n",
    "    OUTPUT_DIR = \"./output\"\n",
    "    \n",
    "    # Create directories\n",
    "    @staticmethod\n",
    "    def create_directories():\n",
    "        \"\"\"Create necessary directories\"\"\"\n",
    "        dirs = [Config.DATA_DIR, Config.MODELS_DIR, Config.LOGS_DIR, Config.OUTPUT_DIR, Config.SCREENSHOT_DIR]\n",
    "        for dir_path in dirs:\n",
    "            os.makedirs(dir_path, exist_ok=True)\n",
    "    \n",
    "    # Model export settings\n",
    "    EXPORT_FORMAT = \"pt\"  # PyTorch format for local use\n",
    "    MODEL_FILENAME = \"face_detection_model.pt\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4db0a51",
   "metadata": {
    "papermill": {
     "duration": 0.030944,
     "end_time": "2025-07-29T01:17:08.882050",
     "exception": false,
     "start_time": "2025-07-29T01:17:08.851106",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Main Preparation File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b42adc5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T01:17:08.987950Z",
     "iopub.status.busy": "2025-07-29T01:17:08.987558Z",
     "iopub.status.idle": "2025-07-29T01:17:23.696005Z",
     "shell.execute_reply": "2025-07-29T01:17:23.695027Z"
    },
    "papermill": {
     "duration": 14.785031,
     "end_time": "2025-07-29T01:17:23.697430",
     "exception": false,
     "start_time": "2025-07-29T01:17:08.912399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Section 1: Data Preparation ===\n",
      "✅ Found 50 Davido images\n",
      "✅ Found 30 Unknown images\n",
      "✅ Found labels.csv\n",
      "Dataset info saved to: ./output/dataset_info.json\n",
      "Dataset splits saved to: ./output/dataset_splits.pkl\n",
      "Original samples: 80\n",
      "Augmented samples: 800\n",
      "Train samples: 64\n",
      "Val samples: 16\n",
      "Class distribution: {'Davido': 50, 'Unknown': 30}\n",
      "Created data loaders:\n",
      "  Training: 40 batches\n",
      "  Validation: 10 batches\n",
      "Data preparation completed successfully!\n",
      "Testing data loading...\n",
      "Batch shape: torch.Size([16, 3, 160, 160])\n",
      "Labels: tensor([0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Section 1: Data Preparation\n",
    "Loads Kaggle dataset and implements data augmentation for facial detection\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "# from config import Config\n",
    "\n",
    "class FaceRecognitionDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for face recognition (classification)\n",
    "    Loads images and labels from CSV file with augmentation\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, csv_file, transform=None, split='train', train_split=0.8, augment_factor=10):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "        self.train_split = train_split\n",
    "        self.augment_factor = augment_factor\n",
    "        \n",
    "        # Load CSV file\n",
    "        csv_path = os.path.join(data_dir, csv_file)\n",
    "        if not os.path.exists(csv_path):\n",
    "            raise FileNotFoundError(f\"CSV file not found: {csv_path}\")\n",
    "        \n",
    "        df = pd.read_csv(csv_path)\n",
    "        df = df[df['label'].isin(Config.CLASS_NAMES)]\n",
    "        \n",
    "        # Create synthetic negative samples for balanced dataset\n",
    "        self.samples = self._create_balanced_dataset(df)\n",
    "        \n",
    "        # Split data\n",
    "        random.shuffle(self.samples)\n",
    "        split_idx = int(len(self.samples) * train_split)\n",
    "        \n",
    "        if split == 'train':\n",
    "            self.samples = self.samples[:split_idx]\n",
    "        else:\n",
    "            self.samples = self.samples[split_idx:]\n",
    "        \n",
    "        # Create augmented samples\n",
    "        self.augmented_samples = self._create_augmented_samples()\n",
    "    \n",
    "    def _create_balanced_dataset(self, df):\n",
    "        \"\"\"Create a balanced dataset with real negative samples\"\"\"\n",
    "        samples = []\n",
    "        \n",
    "        # Add all samples from the CSV\n",
    "        for _, row in df.iterrows():\n",
    "            samples.append((row['filename'], row['label']))\n",
    "        \n",
    "        return samples\n",
    "    \n",
    "    def _create_augmented_samples(self):\n",
    "        \"\"\"Create multiple augmented versions of each image\"\"\"\n",
    "        augmented_samples = []\n",
    "        \n",
    "        for filename, label in self.samples:\n",
    "            # Add original sample\n",
    "            augmented_samples.append((filename, label, 0))  # 0 = original\n",
    "            \n",
    "            # Add augmented versions\n",
    "            for i in range(1, self.augment_factor):\n",
    "                augmented_samples.append((filename, label, i))  # i = augmented version\n",
    "        \n",
    "        return augmented_samples\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.augmented_samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        fname, label, aug_idx = self.augmented_samples[idx]\n",
    "        \n",
    "        # Construct correct path based on label\n",
    "        if label == 'Davido':\n",
    "            img_path = os.path.join(self.data_dir, 'Davido', fname)\n",
    "        else:  # Unknown\n",
    "            img_path = os.path.join(self.data_dir, 'Unknown', fname)\n",
    "        \n",
    "        # Debug: Check if file exists\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"❌ File not found: {img_path}\")\n",
    "            print(f\"  Filename: {fname}\")\n",
    "            print(f\"  Label: {label}\")\n",
    "            print(f\"  Data dir: {self.data_dir}\")\n",
    "            # List available files in the directory\n",
    "            if label == 'Davido':\n",
    "                davido_dir = os.path.join(self.data_dir, 'Davido')\n",
    "                if os.path.exists(davido_dir):\n",
    "                    available_files = os.listdir(davido_dir)\n",
    "                    print(f\"  Available Davido files: {available_files[:5]}...\")\n",
    "            else:\n",
    "                unknown_dir = os.path.join(self.data_dir, 'Unknown')\n",
    "                if os.path.exists(unknown_dir):\n",
    "                    available_files = os.listdir(unknown_dir)\n",
    "                    print(f\"  Available Unknown files: {available_files[:5]}...\")\n",
    "            raise FileNotFoundError(f\"Image file not found: {img_path}\")\n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label_idx = Config.CLASS_NAMES.index(label)\n",
    "        \n",
    "        # Apply augmentation based on aug_idx\n",
    "        if aug_idx == 0:\n",
    "            # Original image with minimal transforms\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "        else:\n",
    "            # Apply moderate augmentation for all samples\n",
    "            image = self._apply_augmentation(image, aug_idx)\n",
    "        \n",
    "        return {'image': image, 'label': label_idx, 'image_path': img_path}\n",
    "    \n",
    "    def _apply_augmentation(self, image, aug_idx):\n",
    "        \"\"\"Apply moderate augmentation for all samples\"\"\"\n",
    "        # Set random seed for reproducible augmentation\n",
    "        random.seed(aug_idx)\n",
    "        np.random.seed(aug_idx)\n",
    "        \n",
    "        # Apply moderate augmentation for all samples\n",
    "        aug_transform = transforms.Compose([\n",
    "            transforms.Resize((Config.IMAGE_SIZE[0] + 20, Config.IMAGE_SIZE[1] + 20)),\n",
    "            transforms.RandomCrop(Config.IMAGE_SIZE),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=15),\n",
    "            transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "            transforms.RandomGrayscale(p=0.1),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "            transforms.RandomErasing(p=0.2, scale=(0.02, 0.2)),\n",
    "        ])\n",
    "        \n",
    "        return aug_transform(image)\n",
    "\n",
    "def get_transforms():\n",
    "    \"\"\"Comprehensive data augmentation for small datasets\"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((Config.IMAGE_SIZE[0] + 20, Config.IMAGE_SIZE[1] + 20)),  # Slightly larger for cropping\n",
    "        transforms.RandomCrop(Config.IMAGE_SIZE),  # Random crop\n",
    "        transforms.RandomHorizontalFlip(p=0.5),  # Random horizontal flip\n",
    "        transforms.RandomRotation(degrees=15),  # Random rotation\n",
    "        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),  # Color augmentation\n",
    "        transforms.RandomGrayscale(p=0.1),  # Random grayscale\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),  # Affine transforms\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "        transforms.RandomErasing(p=0.2, scale=(0.02, 0.2)),  # Random erasing\n",
    "    ])\n",
    "\n",
    "def get_val_transforms():\n",
    "    \"\"\"Simple transforms for validation (no augmentation)\"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(Config.IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "\n",
    "class DatasetManager:\n",
    "    \"\"\"\n",
    "    Manages dataset preparation and loading for face recognition\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize dataset manager\"\"\"\n",
    "        # Check if data directory exists\n",
    "        if not os.path.exists(Config.DATA_DIR):\n",
    "            print(f\"❌ Data directory not found: {Config.DATA_DIR}\")\n",
    "            print(\"Please ensure your data is uploaded to Kaggle with the correct structure:\")\n",
    "            print(\"  /kaggle/input/input-data/\")\n",
    "            print(\"  ├── Davido/     (50 images)\")\n",
    "            print(\"  ├── Unknown/    (30 images)\")\n",
    "            print(\"  └── labels.csv\")\n",
    "            return\n",
    "        \n",
    "        # Verify data structure\n",
    "        davido_dir = os.path.join(Config.DATA_DIR, 'Davido')\n",
    "        unknown_dir = os.path.join(Config.DATA_DIR, 'Unknown')\n",
    "        labels_file = os.path.join(Config.DATA_DIR, 'labels.csv')\n",
    "        \n",
    "        if not os.path.exists(davido_dir):\n",
    "            print(f\"❌ Davido directory not found: {davido_dir}\")\n",
    "        else:\n",
    "            davido_count = len([f for f in os.listdir(davido_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "            print(f\"✅ Found {davido_count} Davido images\")\n",
    "        \n",
    "        if not os.path.exists(unknown_dir):\n",
    "            print(f\"❌ Unknown directory not found: {unknown_dir}\")\n",
    "        else:\n",
    "            unknown_count = len([f for f in os.listdir(unknown_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "            print(f\"✅ Found {unknown_count} Unknown images\")\n",
    "        \n",
    "        if not os.path.exists(labels_file):\n",
    "            print(f\"❌ Labels file not found: {labels_file}\")\n",
    "        else:\n",
    "            print(f\"✅ Found labels.csv\")\n",
    "        \n",
    "        Config.create_directories()\n",
    "    \n",
    "    def prepare_data_loaders(self):\n",
    "        csv_file = 'labels.csv'\n",
    "        train_dataset = FaceRecognitionDataset(\n",
    "            Config.DATA_DIR,\n",
    "            csv_file=csv_file,\n",
    "            transform=get_transforms(),\n",
    "            split='train',\n",
    "            train_split=Config.TRAIN_SPLIT,\n",
    "            augment_factor=10  # Create 10 versions of each image\n",
    "        )\n",
    "        val_dataset = FaceRecognitionDataset(\n",
    "            Config.DATA_DIR,\n",
    "            csv_file=csv_file,\n",
    "            transform=get_val_transforms(),\n",
    "            split='val',\n",
    "            train_split=Config.TRAIN_SPLIT,\n",
    "            augment_factor=10\n",
    "        )\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=Config.BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            num_workers=min(Config.CPU_CORES, 4),\n",
    "            pin_memory=True,\n",
    "            drop_last=True\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=Config.BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=min(Config.CPU_CORES, 4),\n",
    "            pin_memory=True\n",
    "        )\n",
    "        print(f\"Created data loaders:\")\n",
    "        print(f\"  Training: {len(train_loader)} batches\")\n",
    "        print(f\"  Validation: {len(val_loader)} batches\")\n",
    "        return train_loader, val_loader\n",
    "    \n",
    "    def save_dataset_info(self):\n",
    "        \"\"\"Save dataset information for other stages\"\"\"\n",
    "        csv_file = 'labels.csv'\n",
    "        df = pd.read_csv(os.path.join(Config.DATA_DIR, csv_file))\n",
    "        df = df[df['label'].isin(Config.CLASS_NAMES)]\n",
    "        \n",
    "        # Calculate augmented dataset size\n",
    "        original_samples = len(df)\n",
    "        augmented_samples = original_samples * 10  # 10x augmentation\n",
    "        \n",
    "        # Save dataset statistics\n",
    "        dataset_info = {\n",
    "            'total_samples': original_samples,\n",
    "            'augmented_samples': augmented_samples,\n",
    "            'augment_factor': 10,\n",
    "            'class_names': Config.CLASS_NAMES,\n",
    "            'num_classes': Config.NUM_CLASSES,\n",
    "            'train_split': Config.TRAIN_SPLIT,\n",
    "            'val_split': Config.VAL_SPLIT,\n",
    "            'image_size': Config.IMAGE_SIZE,\n",
    "            'batch_size': Config.BATCH_SIZE,\n",
    "            'class_distribution': df['label'].value_counts().to_dict(),\n",
    "            'data_dir': Config.DATA_DIR,\n",
    "            'csv_file': csv_file\n",
    "        }\n",
    "        \n",
    "        # Save to JSON\n",
    "        info_path = os.path.join(Config.OUTPUT_DIR, 'dataset_info.json')\n",
    "        with open(info_path, 'w') as f:\n",
    "            json.dump(dataset_info, f, indent=2)\n",
    "        \n",
    "        # Save train/val splits\n",
    "        train_samples = []\n",
    "        val_samples = []\n",
    "        \n",
    "        # Create the same splits as in the dataset\n",
    "        all_samples = list(zip(df['filename'], df['label']))\n",
    "        random.shuffle(all_samples)\n",
    "        split_idx = int(len(all_samples) * Config.TRAIN_SPLIT)\n",
    "        \n",
    "        train_samples = all_samples[:split_idx]\n",
    "        val_samples = all_samples[split_idx:]\n",
    "        \n",
    "        splits_data = {\n",
    "            'train_samples': train_samples,\n",
    "            'val_samples': val_samples,\n",
    "            'class_names': Config.CLASS_NAMES\n",
    "        }\n",
    "        \n",
    "        splits_path = os.path.join(Config.OUTPUT_DIR, 'dataset_splits.pkl')\n",
    "        with open(splits_path, 'wb') as f:\n",
    "            pickle.dump(splits_data, f)\n",
    "        \n",
    "        print(f\"Dataset info saved to: {info_path}\")\n",
    "        print(f\"Dataset splits saved to: {splits_path}\")\n",
    "        print(f\"Original samples: {original_samples}\")\n",
    "        print(f\"Augmented samples: {augmented_samples}\")\n",
    "        print(f\"Train samples: {len(train_samples)}\")\n",
    "        print(f\"Val samples: {len(val_samples)}\")\n",
    "        print(f\"Class distribution: {dataset_info['class_distribution']}\")\n",
    "        \n",
    "        return dataset_info\n",
    "\n",
    "def main():\n",
    "    print(\"=== Section 1: Data Preparation ===\")\n",
    "    dataset_manager = DatasetManager()\n",
    "    \n",
    "    # Save dataset information for other stages\n",
    "    dataset_info = dataset_manager.save_dataset_info()\n",
    "    \n",
    "    # Test data loading\n",
    "    train_loader, val_loader = dataset_manager.prepare_data_loaders()\n",
    "    if train_loader is not None:\n",
    "        print(\"Data preparation completed successfully!\")\n",
    "        print(\"Testing data loading...\")\n",
    "        for batch in train_loader:\n",
    "            print(f\"Batch shape: {batch['image'].shape}\")\n",
    "            print(f\"Labels: {batch['label']}\")\n",
    "            break\n",
    "    else:\n",
    "        print(\"Data preparation failed. Please check dataset availability.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7961995,
     "sourceId": 12605156,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 102.800816,
   "end_time": "2025-07-29T01:17:25.049670",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-29T01:15:42.248854",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
