{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87898bf6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-28T20:28:47.222169Z",
     "iopub.status.busy": "2025-07-28T20:28:47.221919Z",
     "iopub.status.idle": "2025-07-28T20:30:00.805140Z",
     "shell.execute_reply": "2025-07-28T20:30:00.804174Z"
    },
    "papermill": {
     "duration": 73.58771,
     "end_time": "2025-07-28T20:30:00.806837",
     "exception": false,
     "start_time": "2025-07-28T20:28:47.219127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m108.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q torch torchvision opencv-python numpy Pillow matplotlib albumentations tqdm  scikit-learn tensorboard optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8ad0818",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T20:30:00.849030Z",
     "iopub.status.busy": "2025-07-28T20:30:00.848775Z",
     "iopub.status.idle": "2025-07-28T20:30:00.855651Z",
     "shell.execute_reply": "2025-07-28T20:30:00.855133Z"
    },
    "papermill": {
     "duration": 0.028672,
     "end_time": "2025-07-28T20:30:00.856789",
     "exception": false,
     "start_time": "2025-07-28T20:30:00.828117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Configuration file for Facial Detection System\n",
    "Optimized for Kaggle hardware constraints\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "class Config:\n",
    "    # Hardware constraints for Kaggle\n",
    "    GPU_MEMORY_LIMIT = 14  # GB (leaving 2GB buffer)\n",
    "    RAM_LIMIT = 28  # GB (leaving 4GB buffer)\n",
    "    CPU_CORES = 4\n",
    "    \n",
    "    # Dataset settings\n",
    "    DATASET_NAME = \"davido-recognition\"  # Custom Davido recognition dataset\n",
    "    TRAIN_SPLIT = 0.8\n",
    "    VAL_SPLIT = 0.2\n",
    "    IMAGE_SIZE = (160, 160)  # Standard for face recognition models (e.g., FaceNet)\n",
    "    BATCH_SIZE = 16  # Optimized for P100 GPU memory\n",
    "    DAVIDO_LABEL = \"Davido\"\n",
    "    UNKNOWN_LABEL = \"Unknown\"\n",
    "    CLASS_NAMES = [DAVIDO_LABEL, UNKNOWN_LABEL]\n",
    "    NUM_CLASSES = 2\n",
    "    \n",
    "    # Data augmentation settings\n",
    "    AUGMENTATION_PROBABILITY = 0.8\n",
    "    ROTATION_RANGE = 15\n",
    "    BRIGHTNESS_RANGE = 0.2\n",
    "    CONTRAST_RANGE = 0.2\n",
    "    HORIZONTAL_FLIP_PROB = 0.5\n",
    "    VERTICAL_FLIP_PROB = 0.0  # Keep faces upright\n",
    "    \n",
    "    # Model settings\n",
    "    MODEL_TYPE = \"mobilenet_v2\"  # Lightweight and efficient for classification\n",
    "    PRETRAINED = True\n",
    "    CONFIDENCE_THRESHOLD = 0.5\n",
    "    NMS_THRESHOLD = 0.4\n",
    "    \n",
    "    # Training settings\n",
    "    EPOCHS = 50\n",
    "    LEARNING_RATE = 0.001\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    SCHEDULER_STEP_SIZE = 10\n",
    "    SCHEDULER_GAMMA = 0.5\n",
    "    \n",
    "    # Real-time detection settings\n",
    "    FPS_TARGET = 15  # Process every 4th frame at 60fps\n",
    "    FRAME_SKIP = 4\n",
    "    DETECTION_INTERVAL = 3  # frames between detections\n",
    "    \n",
    "    # Paths\n",
    "    DATA_DIR = \"/kaggle/input/input-images-davido\"\n",
    "    SCREENSHOT_DIR = \"./output/screenshots\"\n",
    "    MODELS_DIR = \"./models\"\n",
    "    LOGS_DIR = \"./logs\"\n",
    "    OUTPUT_DIR = \"./output\"\n",
    "    \n",
    "    # Create directories\n",
    "    @staticmethod\n",
    "    def create_directories():\n",
    "        \"\"\"Create necessary directories\"\"\"\n",
    "        dirs = [Config.DATA_DIR, Config.MODELS_DIR, Config.LOGS_DIR, Config.OUTPUT_DIR, Config.SCREENSHOT_DIR]\n",
    "        for dir_path in dirs:\n",
    "            os.makedirs(dir_path, exist_ok=True)\n",
    "    \n",
    "    # Model export settings\n",
    "    EXPORT_FORMAT = \"pt\"  # PyTorch format for local use\n",
    "    MODEL_FILENAME = \"face_detection_model.pt\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de9c7d1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T20:30:00.895603Z",
     "iopub.status.busy": "2025-07-28T20:30:00.895355Z",
     "iopub.status.idle": "2025-07-28T20:30:13.896456Z",
     "shell.execute_reply": "2025-07-28T20:30:13.895623Z"
    },
    "papermill": {
     "duration": 13.022412,
     "end_time": "2025-07-28T20:30:13.897811",
     "exception": false,
     "start_time": "2025-07-28T20:30:00.875399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Section 1: Data Preparation ===\n",
      "Dataset info saved to: ./output/dataset_info.json\n",
      "Dataset splits saved to: ./output/dataset_splits.pkl\n",
      "Original samples: 20\n",
      "Augmented samples: 200\n",
      "Train samples: 16\n",
      "Val samples: 4\n",
      "Class distribution: {'Davido': 20}\n",
      "Created data loaders:\n",
      "  Training: 20 batches\n",
      "  Validation: 5 batches\n",
      "Data preparation completed successfully!\n",
      "Testing data loading...\n",
      "Batch shape: torch.Size([16, 3, 160, 160])\n",
      "Labels: tensor([0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Section 1: Data Preparation\n",
    "Loads Kaggle dataset and implements data augmentation for facial detection\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "# from config import Config\n",
    "\n",
    "class FaceRecognitionDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for face recognition (classification)\n",
    "    Loads images and labels from CSV file with augmentation\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, csv_file, transform=None, split='train', train_split=0.8, augment_factor=10):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "        self.train_split = train_split\n",
    "        self.augment_factor = augment_factor\n",
    "        \n",
    "        # Load CSV file\n",
    "        csv_path = os.path.join(data_dir, csv_file)\n",
    "        if not os.path.exists(csv_path):\n",
    "            raise FileNotFoundError(f\"CSV file not found: {csv_path}\")\n",
    "        \n",
    "        df = pd.read_csv(csv_path)\n",
    "        df = df[df['label'].isin(Config.CLASS_NAMES)]\n",
    "        \n",
    "        # Create synthetic negative samples for balanced dataset\n",
    "        self.samples = self._create_balanced_dataset(df)\n",
    "        \n",
    "        # Split data\n",
    "        random.shuffle(self.samples)\n",
    "        split_idx = int(len(self.samples) * train_split)\n",
    "        \n",
    "        if split == 'train':\n",
    "            self.samples = self.samples[:split_idx]\n",
    "        else:\n",
    "            self.samples = self.samples[split_idx:]\n",
    "        \n",
    "        # Create augmented samples\n",
    "        self.augmented_samples = self._create_augmented_samples()\n",
    "    \n",
    "    def _create_balanced_dataset(self, df):\n",
    "        \"\"\"Create a balanced dataset with synthetic negative samples\"\"\"\n",
    "        samples = []\n",
    "        \n",
    "        # Add original Davido samples\n",
    "        for _, row in df.iterrows():\n",
    "            samples.append((row['filename'], row['label']))\n",
    "        \n",
    "        # Create synthetic negative samples by applying heavy augmentation to Davido images\n",
    "        davido_files = df[df['label'] == 'Davido']['filename'].tolist()\n",
    "        num_negative_samples = len(davido_files)  # Balance the dataset\n",
    "        \n",
    "        for i in range(num_negative_samples):\n",
    "            # Use a Davido image but apply heavy augmentation to make it look different\n",
    "            davido_file = davido_files[i % len(davido_files)]\n",
    "            samples.append((davido_file, 'Unknown'))  # Label as Unknown but will be heavily augmented\n",
    "        \n",
    "        return samples\n",
    "    \n",
    "    def _create_augmented_samples(self):\n",
    "        \"\"\"Create multiple augmented versions of each image\"\"\"\n",
    "        augmented_samples = []\n",
    "        \n",
    "        for filename, label in self.samples:\n",
    "            # Add original sample\n",
    "            augmented_samples.append((filename, label, 0))  # 0 = original\n",
    "            \n",
    "            # Add augmented versions\n",
    "            for i in range(1, self.augment_factor):\n",
    "                augmented_samples.append((filename, label, i))  # i = augmented version\n",
    "        \n",
    "        return augmented_samples\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.augmented_samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        fname, label, aug_idx = self.augmented_samples[idx]\n",
    "        img_path = os.path.join(self.data_dir, fname)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label_idx = Config.CLASS_NAMES.index(label)\n",
    "        \n",
    "        # Apply different augmentation based on aug_idx and label\n",
    "        if aug_idx == 0:\n",
    "            # Original image with minimal transforms\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "        else:\n",
    "            # Apply heavy augmentation\n",
    "            image = self._apply_augmentation(image, aug_idx, label)\n",
    "        \n",
    "        return {'image': image, 'label': label_idx, 'image_path': img_path}\n",
    "    \n",
    "    def _apply_augmentation(self, image, aug_idx, label):\n",
    "        \"\"\"Apply different augmentation based on index and label\"\"\"\n",
    "        # Set random seed for reproducible augmentation\n",
    "        random.seed(aug_idx)\n",
    "        np.random.seed(aug_idx)\n",
    "        \n",
    "        if label == 'Unknown':\n",
    "            # Apply very heavy augmentation for synthetic negative samples\n",
    "            aug_transform = transforms.Compose([\n",
    "                transforms.Resize((Config.IMAGE_SIZE[0] + 40, Config.IMAGE_SIZE[1] + 40)),\n",
    "                transforms.RandomCrop(Config.IMAGE_SIZE),\n",
    "                transforms.RandomHorizontalFlip(p=0.8),\n",
    "                transforms.RandomRotation(degrees=45),\n",
    "                transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.3),\n",
    "                transforms.RandomGrayscale(p=0.3),\n",
    "                transforms.RandomAffine(degrees=30, translate=(0.2, 0.2), scale=(0.7, 1.3)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "                transforms.RandomErasing(p=0.4, scale=(0.1, 0.3)),\n",
    "            ])\n",
    "        else:\n",
    "            # Apply moderate augmentation for Davido samples\n",
    "            aug_transform = transforms.Compose([\n",
    "                transforms.Resize((Config.IMAGE_SIZE[0] + 20, Config.IMAGE_SIZE[1] + 20)),\n",
    "                transforms.RandomCrop(Config.IMAGE_SIZE),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomRotation(degrees=15),\n",
    "                transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "                transforms.RandomGrayscale(p=0.1),\n",
    "                transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "                transforms.RandomErasing(p=0.2, scale=(0.02, 0.2)),\n",
    "            ])\n",
    "        \n",
    "        return aug_transform(image)\n",
    "\n",
    "def get_transforms():\n",
    "    \"\"\"Comprehensive data augmentation for small datasets\"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((Config.IMAGE_SIZE[0] + 20, Config.IMAGE_SIZE[1] + 20)),  # Slightly larger for cropping\n",
    "        transforms.RandomCrop(Config.IMAGE_SIZE),  # Random crop\n",
    "        transforms.RandomHorizontalFlip(p=0.5),  # Random horizontal flip\n",
    "        transforms.RandomRotation(degrees=15),  # Random rotation\n",
    "        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),  # Color augmentation\n",
    "        transforms.RandomGrayscale(p=0.1),  # Random grayscale\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),  # Affine transforms\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "        transforms.RandomErasing(p=0.2, scale=(0.02, 0.2)),  # Random erasing\n",
    "    ])\n",
    "\n",
    "def get_val_transforms():\n",
    "    \"\"\"Simple transforms for validation (no augmentation)\"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(Config.IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "\n",
    "class DatasetManager:\n",
    "    \"\"\"\n",
    "    Manages dataset preparation and loading for face recognition\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize dataset manager\"\"\"\n",
    "        # Copy labels.csv to data directory if it doesn't exist\n",
    "        source_csv = os.path.join('image_inputs', 'labels.csv')\n",
    "        target_csv = os.path.join(Config.DATA_DIR, 'labels.csv')\n",
    "        \n",
    "        if not os.path.exists(target_csv) and os.path.exists(source_csv):\n",
    "            import shutil\n",
    "            shutil.copy2(source_csv, target_csv)\n",
    "            print(f\"Copied labels.csv from {source_csv} to {target_csv}\")\n",
    "        \n",
    "        # Copy image files to data directory if they don't exist\n",
    "        source_dir = 'image_inputs'\n",
    "        target_dir = Config.DATA_DIR\n",
    "        \n",
    "        if os.path.exists(source_dir):\n",
    "            import shutil\n",
    "            for filename in os.listdir(source_dir):\n",
    "                if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png'):\n",
    "                    source_file = os.path.join(source_dir, filename)\n",
    "                    target_file = os.path.join(target_dir, filename)\n",
    "                    if not os.path.exists(target_file):\n",
    "                        shutil.copy2(source_file, target_file)\n",
    "                        print(f\"Copied {filename} to {target_dir}\")\n",
    "        \n",
    "        Config.create_directories()\n",
    "    \n",
    "    def prepare_data_loaders(self):\n",
    "        csv_file = 'labels.csv'\n",
    "        train_dataset = FaceRecognitionDataset(\n",
    "            Config.DATA_DIR,\n",
    "            csv_file=csv_file,\n",
    "            transform=get_transforms(),\n",
    "            split='train',\n",
    "            train_split=Config.TRAIN_SPLIT,\n",
    "            augment_factor=10  # Create 10 versions of each image\n",
    "        )\n",
    "        val_dataset = FaceRecognitionDataset(\n",
    "            Config.DATA_DIR,\n",
    "            csv_file=csv_file,\n",
    "            transform=get_val_transforms(),\n",
    "            split='val',\n",
    "            train_split=Config.TRAIN_SPLIT,\n",
    "            augment_factor=10\n",
    "        )\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=Config.BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            num_workers=min(Config.CPU_CORES, 4),\n",
    "            pin_memory=True,\n",
    "            drop_last=True\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=Config.BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=min(Config.CPU_CORES, 4),\n",
    "            pin_memory=True\n",
    "        )\n",
    "        print(f\"Created data loaders:\")\n",
    "        print(f\"  Training: {len(train_loader)} batches\")\n",
    "        print(f\"  Validation: {len(val_loader)} batches\")\n",
    "        return train_loader, val_loader\n",
    "    \n",
    "    def save_dataset_info(self):\n",
    "        \"\"\"Save dataset information for other stages\"\"\"\n",
    "        csv_file = 'labels.csv'\n",
    "        df = pd.read_csv(os.path.join(Config.DATA_DIR, csv_file))\n",
    "        df = df[df['label'].isin(Config.CLASS_NAMES)]\n",
    "        \n",
    "        # Calculate augmented dataset size\n",
    "        original_samples = len(df)\n",
    "        augmented_samples = original_samples * 10  # 10x augmentation\n",
    "        \n",
    "        # Save dataset statistics\n",
    "        dataset_info = {\n",
    "            'total_samples': original_samples,\n",
    "            'augmented_samples': augmented_samples,\n",
    "            'augment_factor': 10,\n",
    "            'class_names': Config.CLASS_NAMES,\n",
    "            'num_classes': Config.NUM_CLASSES,\n",
    "            'train_split': Config.TRAIN_SPLIT,\n",
    "            'val_split': Config.VAL_SPLIT,\n",
    "            'image_size': Config.IMAGE_SIZE,\n",
    "            'batch_size': Config.BATCH_SIZE,\n",
    "            'class_distribution': df['label'].value_counts().to_dict(),\n",
    "            'data_dir': Config.DATA_DIR,\n",
    "            'csv_file': csv_file\n",
    "        }\n",
    "        \n",
    "        # Save to JSON\n",
    "        info_path = os.path.join(Config.OUTPUT_DIR, 'dataset_info.json')\n",
    "        with open(info_path, 'w') as f:\n",
    "            json.dump(dataset_info, f, indent=2)\n",
    "        \n",
    "        # Save train/val splits\n",
    "        train_samples = []\n",
    "        val_samples = []\n",
    "        \n",
    "        # Create the same splits as in the dataset\n",
    "        all_samples = list(zip(df['filename'], df['label']))\n",
    "        random.shuffle(all_samples)\n",
    "        split_idx = int(len(all_samples) * Config.TRAIN_SPLIT)\n",
    "        \n",
    "        train_samples = all_samples[:split_idx]\n",
    "        val_samples = all_samples[split_idx:]\n",
    "        \n",
    "        splits_data = {\n",
    "            'train_samples': train_samples,\n",
    "            'val_samples': val_samples,\n",
    "            'class_names': Config.CLASS_NAMES\n",
    "        }\n",
    "        \n",
    "        splits_path = os.path.join(Config.OUTPUT_DIR, 'dataset_splits.pkl')\n",
    "        with open(splits_path, 'wb') as f:\n",
    "            pickle.dump(splits_data, f)\n",
    "        \n",
    "        print(f\"Dataset info saved to: {info_path}\")\n",
    "        print(f\"Dataset splits saved to: {splits_path}\")\n",
    "        print(f\"Original samples: {original_samples}\")\n",
    "        print(f\"Augmented samples: {augmented_samples}\")\n",
    "        print(f\"Train samples: {len(train_samples)}\")\n",
    "        print(f\"Val samples: {len(val_samples)}\")\n",
    "        print(f\"Class distribution: {dataset_info['class_distribution']}\")\n",
    "        \n",
    "        return dataset_info\n",
    "\n",
    "def main():\n",
    "    print(\"=== Section 1: Data Preparation ===\")\n",
    "    dataset_manager = DatasetManager()\n",
    "    \n",
    "    # Save dataset information for other stages\n",
    "    dataset_info = dataset_manager.save_dataset_info()\n",
    "    \n",
    "    # Test data loading\n",
    "    train_loader, val_loader = dataset_manager.prepare_data_loaders()\n",
    "    if train_loader is not None:\n",
    "        print(\"Data preparation completed successfully!\")\n",
    "        print(\"Testing data loading...\")\n",
    "        for batch in train_loader:\n",
    "            print(f\"Batch shape: {batch['image'].shape}\")\n",
    "            print(f\"Labels: {batch['label']}\")\n",
    "            break\n",
    "    else:\n",
    "        print(\"Data preparation failed. Please check dataset availability.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7959389,
     "sourceId": 12603149,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 93.426392,
   "end_time": "2025-07-28T20:30:16.190505",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-28T20:28:42.764113",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
