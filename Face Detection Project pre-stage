{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03e11640",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-28T19:24:44.417783Z",
     "iopub.status.busy": "2025-07-28T19:24:44.417504Z",
     "iopub.status.idle": "2025-07-28T19:25:57.327314Z",
     "shell.execute_reply": "2025-07-28T19:25:57.326317Z"
    },
    "papermill": {
     "duration": 72.914177,
     "end_time": "2025-07-28T19:25:57.329001",
     "exception": false,
     "start_time": "2025-07-28T19:24:44.414824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q torch torchvision opencv-python numpy Pillow matplotlib albumentations tqdm  scikit-learn tensorboard optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36b3c7ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T19:25:57.374059Z",
     "iopub.status.busy": "2025-07-28T19:25:57.373786Z",
     "iopub.status.idle": "2025-07-28T19:25:57.381109Z",
     "shell.execute_reply": "2025-07-28T19:25:57.380399Z"
    },
    "papermill": {
     "duration": 0.029637,
     "end_time": "2025-07-28T19:25:57.382272",
     "exception": false,
     "start_time": "2025-07-28T19:25:57.352635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Configuration file for Facial Detection System\n",
    "Optimized for Kaggle hardware constraints\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "class Config:\n",
    "    # Hardware constraints for Kaggle\n",
    "    GPU_MEMORY_LIMIT = 14  # GB (leaving 2GB buffer)\n",
    "    RAM_LIMIT = 28  # GB (leaving 4GB buffer)\n",
    "    CPU_CORES = 4\n",
    "    \n",
    "    # Dataset settings\n",
    "    DATASET_NAME = \"davido-recognition\"  # Custom Davido recognition dataset\n",
    "    TRAIN_SPLIT = 0.8\n",
    "    VAL_SPLIT = 0.2\n",
    "    IMAGE_SIZE = (160, 160)  # Standard for face recognition models (e.g., FaceNet)\n",
    "    BATCH_SIZE = 16  # Optimized for P100 GPU memory\n",
    "    DAVIDO_LABEL = \"Davido\"\n",
    "    UNKNOWN_LABEL = \"Unknown\"\n",
    "    CLASS_NAMES = [DAVIDO_LABEL, UNKNOWN_LABEL]\n",
    "    NUM_CLASSES = 2\n",
    "    \n",
    "    # Data augmentation settings\n",
    "    AUGMENTATION_PROBABILITY = 0.8\n",
    "    ROTATION_RANGE = 15\n",
    "    BRIGHTNESS_RANGE = 0.2\n",
    "    CONTRAST_RANGE = 0.2\n",
    "    HORIZONTAL_FLIP_PROB = 0.5\n",
    "    VERTICAL_FLIP_PROB = 0.0  # Keep faces upright\n",
    "    \n",
    "    # Model settings\n",
    "    MODEL_TYPE = \"mobilenet_v3\"  # Lightweight and efficient\n",
    "    PRETRAINED = True\n",
    "    NUM_CLASSES = 1  # Face detection only\n",
    "    CONFIDENCE_THRESHOLD = 0.5\n",
    "    NMS_THRESHOLD = 0.4\n",
    "    \n",
    "    # Training settings\n",
    "    EPOCHS = 50\n",
    "    LEARNING_RATE = 0.001\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    SCHEDULER_STEP_SIZE = 10\n",
    "    SCHEDULER_GAMMA = 0.5\n",
    "    \n",
    "    # Real-time detection settings\n",
    "    FPS_TARGET = 15  # Process every 4th frame at 60fps\n",
    "    FRAME_SKIP = 4\n",
    "    DETECTION_INTERVAL = 3  # frames between detections\n",
    "    \n",
    "    # Paths\n",
    "    DATA_DIR = \"/kaggle/input/input-images-davido\"\n",
    "    SCREENSHOT_DIR = \"./output/screenshots\"\n",
    "    MODELS_DIR = \"./models\"\n",
    "    LOGS_DIR = \"./logs\"\n",
    "    OUTPUT_DIR = \"./output\"\n",
    "    \n",
    "    # Create directories\n",
    "    @staticmethod\n",
    "    def create_directories():\n",
    "        \"\"\"Create necessary directories\"\"\"\n",
    "        dirs = [Config.DATA_DIR, Config.MODELS_DIR, Config.LOGS_DIR, Config.OUTPUT_DIR, Config.SCREENSHOT_DIR]\n",
    "        for dir_path in dirs:\n",
    "            os.makedirs(dir_path, exist_ok=True)\n",
    "    \n",
    "    # Model export settings\n",
    "    EXPORT_FORMAT = \"pt\"  # PyTorch format for local use\n",
    "    MODEL_FILENAME = \"face_detection_model.pt\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dee001f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T19:25:57.423746Z",
     "iopub.status.busy": "2025-07-28T19:25:57.423509Z",
     "iopub.status.idle": "2025-07-28T19:26:09.124997Z",
     "shell.execute_reply": "2025-07-28T19:26:09.124003Z"
    },
    "papermill": {
     "duration": 11.723657,
     "end_time": "2025-07-28T19:26:09.126190",
     "exception": false,
     "start_time": "2025-07-28T19:25:57.402533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Section 1: Data Preparation ===\n",
      "Dataset info saved to: ./output/dataset_info.json\n",
      "Dataset splits saved to: ./output/dataset_splits.pkl\n",
      "Total samples: 20\n",
      "Train samples: 16\n",
      "Val samples: 4\n",
      "Class distribution: {'Davido': 20}\n",
      "Created data loaders:\n",
      "  Training: 1 batches\n",
      "  Validation: 1 batches\n",
      "Data preparation completed successfully!\n",
      "Testing data loading...\n",
      "Batch shape: torch.Size([16, 3, 160, 160])\n",
      "Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Section 1: Data Preparation\n",
    "Loads Kaggle dataset and implements data augmentation for facial detection\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# from config import Config\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "class FaceRecognitionDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for face recognition (classification)\n",
    "    Loads images and labels from a CSV file (filename,label)\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, csv_file, transform=None, split='train', train_split=0.8):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.class_names = Config.CLASS_NAMES\n",
    "        # Read CSV\n",
    "        df = pd.read_csv(os.path.join(data_dir, csv_file))\n",
    "        # Filter to only allowed classes\n",
    "        df = df[df['label'].isin(self.class_names)]\n",
    "        self.samples = list(zip(df['filename'], df['label']))\n",
    "        # Shuffle and split\n",
    "        random.shuffle(self.samples)\n",
    "        split_idx = int(len(self.samples) * train_split)\n",
    "        if split == 'train':\n",
    "            self.samples = self.samples[:split_idx]\n",
    "        else:\n",
    "            self.samples = self.samples[split_idx:]\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        fname, label = self.samples[idx]\n",
    "        img_path = os.path.join(self.data_dir, fname)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label_idx = self.class_names.index(label)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return {'image': image, 'label': label_idx, 'image_path': img_path}\n",
    "\n",
    "def get_transforms():\n",
    "    \"\"\"Comprehensive data augmentation for small datasets\"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((Config.IMAGE_SIZE[0] + 20, Config.IMAGE_SIZE[1] + 20)),  # Slightly larger for cropping\n",
    "        transforms.RandomCrop(Config.IMAGE_SIZE),  # Random crop\n",
    "        transforms.RandomHorizontalFlip(p=0.5),  # Random horizontal flip\n",
    "        transforms.RandomRotation(degrees=15),  # Random rotation\n",
    "        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),  # Color augmentation\n",
    "        transforms.RandomGrayscale(p=0.1),  # Random grayscale\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),  # Affine transforms\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "        transforms.RandomErasing(p=0.2, scale=(0.02, 0.2)),  # Random erasing\n",
    "    ])\n",
    "\n",
    "def get_val_transforms():\n",
    "    \"\"\"Simple transforms for validation (no augmentation)\"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(Config.IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "\n",
    "class DatasetManager:\n",
    "    \"\"\"\n",
    "    Manages dataset preparation and loading for face recognition\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        Config.create_directories()\n",
    "    def prepare_data_loaders(self):\n",
    "        csv_file = 'labels.csv'\n",
    "        train_dataset = FaceRecognitionDataset(\n",
    "            Config.DATA_DIR,\n",
    "            csv_file=csv_file,\n",
    "            transform=get_transforms(),\n",
    "            split='train',\n",
    "            train_split=Config.TRAIN_SPLIT\n",
    "        )\n",
    "        val_dataset = FaceRecognitionDataset(\n",
    "            Config.DATA_DIR,\n",
    "            csv_file=csv_file,\n",
    "            transform=get_val_transforms(),\n",
    "            split='val',\n",
    "            train_split=Config.TRAIN_SPLIT\n",
    "        )\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=Config.BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            num_workers=min(Config.CPU_CORES, 4),\n",
    "            pin_memory=True,\n",
    "            drop_last=True\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=Config.BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=min(Config.CPU_CORES, 4),\n",
    "            pin_memory=True\n",
    "        )\n",
    "        print(f\"Created data loaders:\")\n",
    "        print(f\"  Training: {len(train_loader)} batches\")\n",
    "        print(f\"  Validation: {len(val_loader)} batches\")\n",
    "        return train_loader, val_loader\n",
    "    \n",
    "    def save_dataset_info(self):\n",
    "        \"\"\"Save dataset information for other stages\"\"\"\n",
    "        csv_file = 'labels.csv'\n",
    "        df = pd.read_csv(os.path.join(Config.DATA_DIR, csv_file))\n",
    "        df = df[df['label'].isin(Config.CLASS_NAMES)]\n",
    "        \n",
    "        # Save dataset statistics\n",
    "        dataset_info = {\n",
    "            'total_samples': len(df),\n",
    "            'class_names': Config.CLASS_NAMES,\n",
    "            'num_classes': Config.NUM_CLASSES,\n",
    "            'train_split': Config.TRAIN_SPLIT,\n",
    "            'val_split': Config.VAL_SPLIT,\n",
    "            'image_size': Config.IMAGE_SIZE,\n",
    "            'batch_size': Config.BATCH_SIZE,\n",
    "            'class_distribution': df['label'].value_counts().to_dict(),\n",
    "            'data_dir': Config.DATA_DIR,\n",
    "            'csv_file': csv_file\n",
    "        }\n",
    "        \n",
    "        # Save to JSON\n",
    "        info_path = os.path.join(Config.OUTPUT_DIR, 'dataset_info.json')\n",
    "        with open(info_path, 'w') as f:\n",
    "            json.dump(dataset_info, f, indent=2)\n",
    "        \n",
    "        # Save train/val splits\n",
    "        train_samples = []\n",
    "        val_samples = []\n",
    "        \n",
    "        # Create the same splits as in the dataset\n",
    "        all_samples = list(zip(df['filename'], df['label']))\n",
    "        random.shuffle(all_samples)\n",
    "        split_idx = int(len(all_samples) * Config.TRAIN_SPLIT)\n",
    "        \n",
    "        train_samples = all_samples[:split_idx]\n",
    "        val_samples = all_samples[split_idx:]\n",
    "        \n",
    "        splits_data = {\n",
    "            'train_samples': train_samples,\n",
    "            'val_samples': val_samples,\n",
    "            'class_names': Config.CLASS_NAMES\n",
    "        }\n",
    "        \n",
    "        splits_path = os.path.join(Config.OUTPUT_DIR, 'dataset_splits.pkl')\n",
    "        with open(splits_path, 'wb') as f:\n",
    "            pickle.dump(splits_data, f)\n",
    "        \n",
    "        print(f\"Dataset info saved to: {info_path}\")\n",
    "        print(f\"Dataset splits saved to: {splits_path}\")\n",
    "        print(f\"Total samples: {len(df)}\")\n",
    "        print(f\"Train samples: {len(train_samples)}\")\n",
    "        print(f\"Val samples: {len(val_samples)}\")\n",
    "        print(f\"Class distribution: {dataset_info['class_distribution']}\")\n",
    "        \n",
    "        return dataset_info\n",
    "\n",
    "def main():\n",
    "    print(\"=== Section 1: Data Preparation ===\")\n",
    "    dataset_manager = DatasetManager()\n",
    "    \n",
    "    # Save dataset information for other stages\n",
    "    dataset_info = dataset_manager.save_dataset_info()\n",
    "    \n",
    "    # Test data loading\n",
    "    train_loader, val_loader = dataset_manager.prepare_data_loaders()\n",
    "    if train_loader is not None:\n",
    "        print(\"Data preparation completed successfully!\")\n",
    "        print(\"Testing data loading...\")\n",
    "        for batch in train_loader:\n",
    "            print(f\"Batch shape: {batch['image'].shape}\")\n",
    "            print(f\"Labels: {batch['label']}\")\n",
    "            break\n",
    "    else:\n",
    "        print(\"Data preparation failed. Please check dataset availability.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7959389,
     "sourceId": 12603149,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 90.145679,
   "end_time": "2025-07-28T19:26:10.467893",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-28T19:24:40.322214",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
