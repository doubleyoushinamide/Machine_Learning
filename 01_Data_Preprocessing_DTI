{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9baa84af",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-16T22:41:28.800906Z",
     "iopub.status.busy": "2025-07-16T22:41:28.800680Z",
     "iopub.status.idle": "2025-07-16T22:42:39.396192Z",
     "shell.execute_reply": "2025-07-16T22:42:39.395243Z"
    },
    "papermill": {
     "duration": 70.599459,
     "end_time": "2025-07-16T22:42:39.397811",
     "exception": false,
     "start_time": "2025-07-16T22:41:28.798352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install --quiet pandas numpy scikit-learn torch transformers rdkit-pypi fair-esm optuna matplotlib seaborn scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "840daf5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T22:42:39.432163Z",
     "iopub.status.busy": "2025-07-16T22:42:39.431550Z",
     "iopub.status.idle": "2025-07-16T22:53:42.351249Z",
     "shell.execute_reply": "2025-07-16T22:53:42.350450Z"
    },
    "papermill": {
     "duration": 662.937337,
     "end_time": "2025-07-16T22:53:42.352379",
     "exception": false,
     "start_time": "2025-07-16T22:42:39.415042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/2832144492.py:42: DtypeWarning: Columns (0,9,10,11,13,14,15,16,17,18,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path)\n",
      "/tmp/ipykernel_19/2832144492.py:42: DtypeWarning: Columns (0,9,10,11,13,14,15,16,17,18,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path)\n",
      "/tmp/ipykernel_19/2832144492.py:42: DtypeWarning: Columns (0,9,10,11,13,14,15,16,17,18,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path)\n",
      "/tmp/ipykernel_19/2832144492.py:42: DtypeWarning: Columns (0,2,9,10,11,12,14,15,16,17,18,19,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed merged AID DTI: 180669 entries.\n",
      "Processed AID merged DTI data saved to 'processed_aid_merged_dti.csv'\n",
      "Processed merged AID DTI data saved to 'processed_merged_all_dti.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem, RDLogger\n",
    "from rdkit.Chem import SaltRemover\n",
    "\n",
    "# Disable RDKit logging to reduce output clutter\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "# Configuration\n",
    "AID_PATHS = [\n",
    "    '/kaggle/input/punched-aid/AID_504832.csv',\n",
    "    '/kaggle/input/punched-aid/AID_504834.csv',\n",
    "    '/kaggle/input/pubchem-test-sets/AID_504834.csv',  \n",
    "    '/kaggle/input/pubchem-test-sets/AID_720542.csv'  \n",
    "]\n",
    "SMILES_COLUMN_AIDs = 'PUBCHEM_EXT_DATASOURCE_SMILES'\n",
    "TARGET_COLUMN_AID = 'Fit_LogAC50'\n",
    "\n",
    "# Fixed PfDHODH protein sequence\n",
    "PF_DHODH_SEQUENCE = \"MISKLKPQFMFLPKKHILSYCRKDVLNLFEQKFYYTSKRKESNNMKNESLLRLINYNRYYNKIDSNNYYNGGKILSNDRQYIYSPLCEYKKKINDISSYVSVPFKINIRNLGTSNFVNNKKDVLDNDYIYENIKKEKSKHKKIIFLLFVSLFGLYGFFESYNPEFFLYDIFLKFCLKYIDGEICHDLFLLLGKYNILPYDTSNDSIYACTNIKHLDFINPFGVAAGFDKNGVCIDSILKLGFSFIEIGTITPRGQTGNAKPRIFRDVESRSIINSCGFNNMGCDKVTENLILFRKRQEEDKLLSKHIVGVSIGKNKDTVNIVDDLKYCINKIGRYADYIAINVSSPNTPGLRDNQEAGKLKNIILSVKEEIDNLEKNNIMNDESTYNEDNKIVEKKNNFNKNNSHMMKDAKDNFLWFNTTKKKPLVFVKLAPDLNQEQKKEIADVLLETNIDGMIISNTTTQINDIKSFENKKGGVSGAKLKDISTKFICEMYNYTNKQIPIIASGGIFSGLDALEKIEAGASVCQLYSCLVFNGMKSAVQIKRELNHLLYQRGYYNLKEAIGRKHSKS\"\n",
    "\n",
    "# Helper Functions\n",
    "def standardize_smiles(smiles, remover):\n",
    "    \"\"\"Standardize SMILES strings by canonicalizing and removing salts.\"\"\"\n",
    "    if pd.isna(smiles):\n",
    "        return None\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol:\n",
    "            mol = remover.StripMol(mol)\n",
    "            return Chem.MolToSmiles(mol, canonical=True)\n",
    "        return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Process AID Datasets\n",
    "def process_aid_in_chunks(paths, remover):\n",
    "    \"\"\"Process AID datasets and merge them.\"\"\"\n",
    "    processed_chunks = []\n",
    "    for path in paths:\n",
    "        try:\n",
    "            df = pd.read_csv(path)\n",
    "            if SMILES_COLUMN_AIDs not in df or TARGET_COLUMN_AID not in df:\n",
    "                print(f\"Missing columns in {path}. Skipping.\")\n",
    "                continue\n",
    "            # Select and rename relevant columns\n",
    "            df = df[[SMILES_COLUMN_AIDs, TARGET_COLUMN_AID]].copy()\n",
    "            df.rename(columns={SMILES_COLUMN_AIDs: 'SMILES', TARGET_COLUMN_AID: 'pAC50'}, inplace=True)\n",
    "            # Standardize SMILES\n",
    "            df['SMILES'] = df['SMILES'].apply(lambda x: standardize_smiles(x, remover))\n",
    "            df.dropna(subset=['SMILES'], inplace=True)\n",
    "            # Ensure pAC50 is numeric\n",
    "            df['pAC50'] = pd.to_numeric(df['pAC50'], errors='coerce')\n",
    "            df.dropna(subset=['pAC50'], inplace=True)\n",
    "            # Add protein sequence\n",
    "            df['Protein_Sequence'] = PF_DHODH_SEQUENCE\n",
    "            processed_chunks.append(df[['SMILES', 'Protein_Sequence', 'pAC50']])\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: AID file not found at {path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {path}: {e}\")\n",
    "    if processed_chunks:\n",
    "        df = pd.concat(processed_chunks, ignore_index=True)\n",
    "        df.drop_duplicates(subset=['SMILES', 'Protein_Sequence'], inplace=True)\n",
    "        print(f\"Processed merged AID DTI: {len(df)} entries.\")\n",
    "        return df\n",
    "    else:\n",
    "        print(\"No valid AID DTI data found.\")\n",
    "        return pd.DataFrame(columns=['SMILES', 'Protein_Sequence', 'pAC50'])\n",
    "\n",
    "# Main Execution\n",
    "def main():\n",
    "    \"\"\"Preprocess AID datasets and save output files.\"\"\"\n",
    "    remover = SaltRemover.SaltRemover()\n",
    "\n",
    "    # Process AID datasets\n",
    "    df_aid_merged = process_aid_in_chunks(AID_PATHS, remover)\n",
    "\n",
    "    # Save AID merged data\n",
    "    if not df_aid_merged.empty:\n",
    "        df_aid_merged = df_aid_merged.replace([np.inf, -np.inf], np.nan)\n",
    "        df_aid_merged = df_aid_merged.dropna(subset=['SMILES', 'pAC50', 'Protein_Sequence'])\n",
    "        df_aid_merged.to_csv('processed_aid_merged_dti.csv', index=False)\n",
    "        print(\"Processed AID merged DTI data saved to 'processed_aid_merged_dti.csv'\")\n",
    "    else:\n",
    "        print(\"No AID DTI data to save.\")\n",
    "\n",
    "    # Save merged dataset (same as AID since BindingDB is excluded)\n",
    "    if not df_aid_merged.empty:\n",
    "        df_merged_all = df_aid_merged.copy()\n",
    "        df_merged_all['log_kd'] = np.nan  # Add log_kd column for compatibility\n",
    "        df_merged_all = df_merged_all[['SMILES', 'Protein_Sequence', 'log_kd', 'pAC50']]\n",
    "        df_merged_all.to_csv('processed_merged_all_dti.csv', index=False)\n",
    "        print(\"Processed merged AID DTI data saved to 'processed_merged_all_dti.csv'\")\n",
    "    else:\n",
    "        print(\"No data to merge.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7293458,
     "sourceId": 11625475,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7576939,
     "sourceId": 12041030,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7748531,
     "sourceId": 12293957,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 738.051632,
   "end_time": "2025-07-16T22:53:42.786849",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-16T22:41:24.735217",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
