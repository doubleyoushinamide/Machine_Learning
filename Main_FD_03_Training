{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e93189b7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-29T22:33:57.580093Z",
     "iopub.status.busy": "2025-07-29T22:33:57.579841Z",
     "iopub.status.idle": "2025-07-29T22:35:11.416389Z",
     "shell.execute_reply": "2025-07-29T22:35:11.415255Z"
    },
    "papermill": {
     "duration": 73.841849,
     "end_time": "2025-07-29T22:35:11.418196",
     "exception": false,
     "start_time": "2025-07-29T22:33:57.576347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q torch torchvision opencv-python numpy Pillow matplotlib albumentations tqdm  scikit-learn tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3177e5f",
   "metadata": {
    "papermill": {
     "duration": 0.02594,
     "end_time": "2025-07-29T22:35:11.479343",
     "exception": false,
     "start_time": "2025-07-29T22:35:11.453403",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Config Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4b542d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T22:35:11.554067Z",
     "iopub.status.busy": "2025-07-29T22:35:11.553704Z",
     "iopub.status.idle": "2025-07-29T22:35:11.563958Z",
     "shell.execute_reply": "2025-07-29T22:35:11.563145Z"
    },
    "papermill": {
     "duration": 0.04915,
     "end_time": "2025-07-29T22:35:11.565289",
     "exception": false,
     "start_time": "2025-07-29T22:35:11.516139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Configuration file for Facial Detection System\n",
    "Optimized for Kaggle hardware constraints\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "class Config:\n",
    "    # Hardware constraints for Kaggle\n",
    "    GPU_MEMORY_LIMIT = 14  # GB (leaving 2GB buffer)\n",
    "    RAM_LIMIT = 28  # GB (leaving 4GB buffer)\n",
    "    CPU_CORES = 4\n",
    "    \n",
    "    # Dataset settings\n",
    "    DATASET_NAME = \"davido-recognition\"  # Custom Davido recognition dataset\n",
    "    TRAIN_SPLIT = 0.8\n",
    "    VAL_SPLIT = 0.2\n",
    "    IMAGE_SIZE = (160, 160)  # Standard for face recognition models (e.g., FaceNet)\n",
    "    BATCH_SIZE = 16  # Optimized for P100 GPU memory\n",
    "    DAVIDO_LABEL = \"Davido\"\n",
    "    UNKNOWN_LABEL = \"Unknown\"\n",
    "    CLASS_NAMES = [DAVIDO_LABEL, UNKNOWN_LABEL]\n",
    "    NUM_CLASSES = 2\n",
    "    \n",
    "    # Data augmentation settings\n",
    "    AUGMENTATION_PROBABILITY = 0.8\n",
    "    ROTATION_RANGE = 15\n",
    "    BRIGHTNESS_RANGE = 0.2\n",
    "    CONTRAST_RANGE = 0.2\n",
    "    HORIZONTAL_FLIP_PROB = 0.5\n",
    "    VERTICAL_FLIP_PROB = 0.0  # Keep faces upright\n",
    "    \n",
    "    # Model settings\n",
    "    MODEL_TYPE = \"mobilenet_v2\"  # Lightweight and efficient for classification\n",
    "    PRETRAINED = True\n",
    "    # Confidence threshold for prediction\n",
    "    CONFIDENCE_THRESHOLD = 0.985  # Only recognize Davido if confidence > 0.985\n",
    "    NMS_THRESHOLD = 0.4\n",
    "    \n",
    "    # Training settings (optimized for larger dataset)\n",
    "    EPOCHS = 100  # More epochs for larger dataset\n",
    "    LEARNING_RATE = 0.001\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    SCHEDULER_STEP_SIZE = 15\n",
    "    SCHEDULER_GAMMA = 0.5\n",
    "    \n",
    "    # Early stopping settings (adjusted for larger dataset)\n",
    "    EARLY_STOPPING_PATIENCE = 15  # More patience for larger dataset\n",
    "    EARLY_STOPPING_MIN_DELTA = 0.0005  # Smaller improvement threshold\n",
    "    \n",
    "    # Real-time detection settings\n",
    "    FPS_TARGET = 15  # Process every 4th frame at 60fps\n",
    "    FRAME_SKIP = 4\n",
    "    DETECTION_INTERVAL = 3  # frames between detections\n",
    "    \n",
    "    # Paths (Updated for local use)\n",
    "    DATA_DIR = \"/kaggle/input/input-data\"  # Local data directory (if needed)\n",
    "    SCREENSHOT_DIR = \"./output/screenshots\"\n",
    "    MODELS_DIR = \"./models\"\n",
    "    LOGS_DIR = \"./logs\"\n",
    "    OUTPUT_DIR = \"./output\"\n",
    "    \n",
    "    # Create directories\n",
    "    @staticmethod\n",
    "    def create_directories():\n",
    "        \"\"\"Create necessary directories\"\"\"\n",
    "        dirs = [Config.MODELS_DIR, Config.LOGS_DIR, Config.OUTPUT_DIR, Config.SCREENSHOT_DIR]\n",
    "        for dir_path in dirs:\n",
    "            os.makedirs(dir_path, exist_ok=True)\n",
    "    \n",
    "    # Model export settings\n",
    "    EXPORT_FORMAT = \"pt\"  # PyTorch format for local use\n",
    "    MODEL_FILENAME = \"face_detection_model.pt\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f504dc70",
   "metadata": {
    "papermill": {
     "duration": 0.044465,
     "end_time": "2025-07-29T22:35:11.647753",
     "exception": false,
     "start_time": "2025-07-29T22:35:11.603288",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Loader Utility Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c857110",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T22:35:11.727789Z",
     "iopub.status.busy": "2025-07-29T22:35:11.727539Z",
     "iopub.status.idle": "2025-07-29T22:35:20.920270Z",
     "shell.execute_reply": "2025-07-29T22:35:20.919471Z"
    },
    "papermill": {
     "duration": 9.240521,
     "end_time": "2025-07-29T22:35:20.921777",
     "exception": false,
     "start_time": "2025-07-29T22:35:11.681256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utility functions to load dataset information saved by data_preparation.py\n",
    "Used by hyperparameter tuning and training stages\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "# from config import Config\n",
    "\n",
    "class FaceRecognitionDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for face recognition (classification)\n",
    "    Loads images and labels from saved splits with augmentation\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, samples, transform=None, augment_factor=10):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.samples = samples\n",
    "        self.class_names = Config.CLASS_NAMES\n",
    "        self.augment_factor = augment_factor\n",
    "        \n",
    "        # Create balanced dataset with synthetic negative samples\n",
    "        self.balanced_samples = self._create_balanced_samples()\n",
    "        \n",
    "        # Create augmented samples\n",
    "        self.augmented_samples = self._create_augmented_samples()\n",
    "    \n",
    "    def _create_balanced_samples(self):\n",
    "        \"\"\"Use real samples from the dataset\"\"\"\n",
    "        # Simply return the original samples since we now have real negative samples\n",
    "        return self.samples\n",
    "    \n",
    "    def _create_augmented_samples(self):\n",
    "        \"\"\"Create multiple augmented versions of each image\"\"\"\n",
    "        augmented_samples = []\n",
    "        \n",
    "        for filename, label in self.balanced_samples:\n",
    "            # Add original sample\n",
    "            augmented_samples.append((filename, label, 0))  # 0 = original\n",
    "            \n",
    "            # Add augmented versions\n",
    "            for i in range(1, self.augment_factor):\n",
    "                augmented_samples.append((filename, label, i))  # i = augmented version\n",
    "        \n",
    "        return augmented_samples\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.augmented_samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        fname, label, aug_idx = self.augmented_samples[idx]\n",
    "        \n",
    "        # Construct correct path based on label\n",
    "        if label == 'Davido':\n",
    "            img_path = os.path.join(self.data_dir, 'Davido', fname)\n",
    "        else:  # Unknown\n",
    "            img_path = os.path.join(self.data_dir, 'Unknown', fname)\n",
    "        \n",
    "        # Debug: Check if file exists\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"❌ File not found: {img_path}\")\n",
    "            print(f\"  Filename: {fname}\")\n",
    "            print(f\"  Label: {label}\")\n",
    "            print(f\"  Data dir: {self.data_dir}\")\n",
    "            raise FileNotFoundError(f\"Image file not found: {img_path}\")\n",
    "        \n",
    "        # Try to load image with error handling\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  Corrupted image file: {img_path}\")\n",
    "            print(f\"  Error: {e}\")\n",
    "            print(f\"  Skipping this file and trying next one...\")\n",
    "            \n",
    "            # Try to get next valid sample\n",
    "            for attempt in range(1, min(10, len(self.augmented_samples))):\n",
    "                try:\n",
    "                    next_idx = (idx + attempt) % len(self.augmented_samples)\n",
    "                    next_fname, next_label, next_aug_idx = self.augmented_samples[next_idx]\n",
    "                    \n",
    "                    if next_label == 'Davido':\n",
    "                        next_img_path = os.path.join(self.data_dir, 'Davido', next_fname)\n",
    "                    else:\n",
    "                        next_img_path = os.path.join(self.data_dir, 'Unknown', next_fname)\n",
    "                    \n",
    "                    if os.path.exists(next_img_path):\n",
    "                        image = Image.open(next_img_path).convert('RGB')\n",
    "                        label = next_label\n",
    "                        label_idx = self.class_names.index(label)\n",
    "                        print(f\"  ✅ Successfully loaded alternative image: {next_img_path}\")\n",
    "                        \n",
    "                        # Apply augmentation based on aug_idx\n",
    "                        if next_aug_idx == 0:\n",
    "                            if self.transform:\n",
    "                                image = self.transform(image)\n",
    "                        else:\n",
    "                            image = self._apply_augmentation(image, next_aug_idx, label)\n",
    "                        \n",
    "                        return {'image': image, 'label': label_idx, 'image_path': next_img_path}\n",
    "                        \n",
    "                except Exception as next_e:\n",
    "                    continue\n",
    "            \n",
    "            # If we can't find a valid image, raise the original error\n",
    "            raise Exception(f\"Could not load image after multiple attempts. Original error: {e}\")\n",
    "        \n",
    "        label_idx = self.class_names.index(label)\n",
    "        \n",
    "        # Apply different augmentation based on aug_idx and label\n",
    "        if aug_idx == 0:\n",
    "            # Original image with minimal transforms\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "        else:\n",
    "            # Apply heavy augmentation\n",
    "            image = self._apply_augmentation(image, aug_idx, label)\n",
    "        \n",
    "        return {'image': image, 'label': label_idx, 'image_path': img_path}\n",
    "    \n",
    "    def _apply_augmentation(self, image, aug_idx, label):\n",
    "        \"\"\"Apply different augmentation based on index and label\"\"\"\n",
    "        # Set random seed for reproducible augmentation\n",
    "        import random\n",
    "        import numpy as np\n",
    "        random.seed(aug_idx)\n",
    "        np.random.seed(aug_idx)\n",
    "        \n",
    "        if label == 'Unknown':\n",
    "            # Apply very heavy augmentation for synthetic negative samples\n",
    "            aug_transform = transforms.Compose([\n",
    "                transforms.Resize((Config.IMAGE_SIZE[0] + 40, Config.IMAGE_SIZE[1] + 40)),\n",
    "                transforms.RandomCrop(Config.IMAGE_SIZE),\n",
    "                transforms.RandomHorizontalFlip(p=0.8),\n",
    "                transforms.RandomRotation(degrees=45),\n",
    "                transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.3),\n",
    "                transforms.RandomGrayscale(p=0.3),\n",
    "                transforms.RandomAffine(degrees=30, translate=(0.2, 0.2), scale=(0.7, 1.3)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "                transforms.RandomErasing(p=0.4, scale=(0.1, 0.3)),\n",
    "            ])\n",
    "        else:\n",
    "            # Apply moderate augmentation for Davido samples\n",
    "            aug_transform = transforms.Compose([\n",
    "                transforms.Resize((Config.IMAGE_SIZE[0] + 20, Config.IMAGE_SIZE[1] + 20)),\n",
    "                transforms.RandomCrop(Config.IMAGE_SIZE),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomRotation(degrees=15),\n",
    "                transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "                transforms.RandomGrayscale(p=0.1),\n",
    "                transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "                transforms.RandomErasing(p=0.2, scale=(0.02, 0.2)),\n",
    "            ])\n",
    "        \n",
    "        return aug_transform(image)\n",
    "\n",
    "def get_transforms():\n",
    "    \"\"\"Comprehensive data augmentation for small datasets\"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((Config.IMAGE_SIZE[0] + 20, Config.IMAGE_SIZE[1] + 20)),  # Slightly larger for cropping\n",
    "        transforms.RandomCrop(Config.IMAGE_SIZE),  # Random crop\n",
    "        transforms.RandomHorizontalFlip(p=0.5),  # Random horizontal flip\n",
    "        transforms.RandomRotation(degrees=15),  # Random rotation\n",
    "        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),  # Color augmentation\n",
    "        transforms.RandomGrayscale(p=0.1),  # Random grayscale\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),  # Affine transforms\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "        transforms.RandomErasing(p=0.2, scale=(0.02, 0.2)),  # Random erasing\n",
    "    ])\n",
    "\n",
    "def get_val_transforms():\n",
    "    \"\"\"Simple transforms for validation (no augmentation)\"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(Config.IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "\n",
    "def load_dataset_info():\n",
    "    \"\"\"Load dataset information saved by data_preparation.py\"\"\"\n",
    "    # Try multiple possible paths\n",
    "    possible_paths = [\n",
    "        os.path.join(Config.OUTPUT_DIR, 'dataset_info.json'),\n",
    "        os.path.join('/kaggle/input/fd-01-preprocessing/output', 'dataset_info.json'),\n",
    "        './output/dataset_info.json'\n",
    "    ]\n",
    "    \n",
    "    info_path = None\n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path):\n",
    "            info_path = path\n",
    "            break\n",
    "    \n",
    "    if info_path is None:\n",
    "        raise FileNotFoundError(f\"Dataset info not found. Tried: {possible_paths}. Run data_preparation.py first.\")\n",
    "    \n",
    "    with open(info_path, 'r') as f:\n",
    "        dataset_info = json.load(f)\n",
    "    \n",
    "    print(f\"Loaded dataset info:\")\n",
    "    print(f\"  Total samples: {dataset_info['total_samples']}\")\n",
    "    print(f\"  Classes: {dataset_info['class_names']}\")\n",
    "    print(f\"  Class distribution: {dataset_info['class_distribution']}\")\n",
    "    \n",
    "    return dataset_info\n",
    "\n",
    "def load_dataset_splits():\n",
    "    \"\"\"Load train/val splits saved by data_preparation.py\"\"\"\n",
    "    # Try multiple possible paths\n",
    "    possible_paths = [\n",
    "        os.path.join(Config.OUTPUT_DIR, 'dataset_splits.pkl'),\n",
    "        os.path.join('/kaggle/input/fd-01-preprocessing/output', 'dataset_splits.pkl'),\n",
    "        './output/dataset_splits.pkl'\n",
    "    ]\n",
    "    \n",
    "    splits_path = None\n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path):\n",
    "            splits_path = path\n",
    "            break\n",
    "    \n",
    "    if splits_path is None:\n",
    "        raise FileNotFoundError(f\"Dataset splits not found. Tried: {possible_paths}. Run data_preparation.py first.\")\n",
    "    \n",
    "    with open(splits_path, 'rb') as f:\n",
    "        splits_data = pickle.load(f)\n",
    "    \n",
    "    return splits_data['train_samples'], splits_data['val_samples'], splits_data['class_names']\n",
    "\n",
    "def create_data_loaders(batch_size=None, num_workers=None):\n",
    "    \"\"\"Create train and validation data loaders from saved splits\"\"\"\n",
    "    if batch_size is None:\n",
    "        batch_size = Config.BATCH_SIZE\n",
    "    if num_workers is None:\n",
    "        num_workers = min(Config.CPU_CORES, 4)\n",
    "    \n",
    "    # Load saved splits\n",
    "    train_samples, val_samples, class_names = load_dataset_splits()\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = FaceRecognitionDataset(\n",
    "        Config.DATA_DIR,\n",
    "        train_samples,\n",
    "        transform=get_transforms()\n",
    "    )\n",
    "    \n",
    "    val_dataset = FaceRecognitionDataset(\n",
    "        Config.DATA_DIR,\n",
    "        val_samples,\n",
    "        transform=get_val_transforms()\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Created data loaders:\")\n",
    "    print(f\"  Training: {len(train_loader)} batches\")\n",
    "    print(f\"  Validation: {len(val_loader)} batches\")\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "def test_data_loading():\n",
    "    \"\"\"Test function to verify data loading works\"\"\"\n",
    "    try:\n",
    "        dataset_info = load_dataset_info()\n",
    "        train_loader, val_loader = create_data_loaders()\n",
    "        \n",
    "        # Test a batch\n",
    "        for batch in train_loader:\n",
    "            print(f\"Test batch shape: {batch['image'].shape}\")\n",
    "            print(f\"Test batch labels: {batch['label']}\")\n",
    "            break\n",
    "        \n",
    "        print(\"✓ Data loading test successful!\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Data loading test failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     test_data_loading() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b8d352",
   "metadata": {
    "papermill": {
     "duration": 0.024898,
     "end_time": "2025-07-29T22:35:20.972393",
     "exception": false,
     "start_time": "2025-07-29T22:35:20.947495",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Main File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "504d3ef4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T22:35:21.079035Z",
     "iopub.status.busy": "2025-07-29T22:35:21.078643Z",
     "iopub.status.idle": "2025-07-29T22:37:25.646492Z",
     "shell.execute_reply": "2025-07-29T22:37:25.645553Z"
    },
    "papermill": {
     "duration": 124.596152,
     "end_time": "2025-07-29T22:37:25.647868",
     "exception": false,
     "start_time": "2025-07-29T22:35:21.051716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 22:35:23.170643: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753828523.364708      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753828523.420860      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Section 2: Model Selection and Training ===\n",
      "Created data loaders:\n",
      "  Training: 40 batches\n",
      "  Validation: 10 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13.6M/13.6M [00:00<00:00, 188MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded best hyperparameters from /kaggle/input/fd-02-hyperparam-tuning/output/best_hyperparameters.json\n",
      "Model initialized on device: cuda\n",
      "Total parameters: 2,226,434\n",
      "Learning rate: 0.000500\n",
      "Weight decay: 0.000010\n",
      "Loss function: CrossEntropyLoss()\n",
      "Early stopping patience: 15\n",
      "Early stopping min delta: 0.0005\n",
      "Model test - Input shape: torch.Size([1, 3, 160, 160])\n",
      "Model test - Output shape: torch.Size([1, 2])\n",
      "Model test - Output range: [0.0170, 0.5140]\n",
      "Loss test - Labels: tensor([1], device='cuda:0')\n",
      "Loss test - Loss value: 0.972213\n",
      "Starting training...\n",
      "Training for 100 epochs (with early stopping)\n",
      "Learning rate: 0.0005\n",
      "Batch size: 16\n",
      "Early stopping patience: 15\n",
      "[DEBUG] Training batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-0.9609, 0.9929]\n",
      "  Loss value: 0.470229\n",
      "  Predicted classes: tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "[DEBUG] Training batch 1:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-1.8767, 2.2727]\n",
      "  Loss value: 0.740866\n",
      "  Predicted classes: tensor([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "[DEBUG] Training batch 2:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-1.8255, 2.5618]\n",
      "  Loss value: 0.273371\n",
      "  Predicted classes: tensor([1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "[DEBUG] Training epoch 0:\n",
      "  Total loss: 10.911510\n",
      "  Num batches: 40\n",
      "  Average loss: 0.272788\n",
      "[DEBUG] Validation batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-6.8300, 5.9669]\n",
      "  Loss value: 0.148065\n",
      "  Predicted classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "[DEBUG] Validation epoch 0:\n",
      "  Total loss: 2.464373\n",
      "  Num batches: 10\n",
      "  Average loss: 0.246437\n",
      "Saved best model with validation loss: 0.2464\n",
      "Epoch 1/100:\n",
      "  Train Loss: 0.2728\n",
      "  Val Loss: 0.2464\n",
      "  Learning Rate: 0.000500\n",
      "  Best Val Loss: 0.2464\n",
      "  Early Stop Counter: 1/15\n",
      "\n",
      "[DEBUG] Training batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-5.4780, 5.9148]\n",
      "  Loss value: 0.204769\n",
      "  Predicted classes: tensor([0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "[DEBUG] Training batch 1:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-4.7918, 5.3825]\n",
      "  Loss value: 0.158149\n",
      "  Predicted classes: tensor([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "[DEBUG] Training batch 2:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-5.4173, 5.0510]\n",
      "  Loss value: 0.052763\n",
      "  Predicted classes: tensor([1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "[DEBUG] Training epoch 1:\n",
      "  Total loss: 5.009934\n",
      "  Num batches: 40\n",
      "  Average loss: 0.125248\n",
      "[DEBUG] Validation batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-11.6973, 13.1728]\n",
      "  Loss value: 0.232588\n",
      "  Predicted classes: tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "[DEBUG] Validation epoch 1:\n",
      "  Total loss: 7.753463\n",
      "  Num batches: 10\n",
      "  Average loss: 0.775346\n",
      "Epoch 2/100:\n",
      "  Train Loss: 0.1252\n",
      "  Val Loss: 0.7753\n",
      "  Learning Rate: 0.000500\n",
      "  Best Val Loss: 0.2464\n",
      "  Early Stop Counter: 2/15\n",
      "\n",
      "[DEBUG] Training batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-7.3352, 6.3753]\n",
      "  Loss value: 0.031725\n",
      "  Predicted classes: tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "[DEBUG] Training batch 1:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-9.9094, 9.4540]\n",
      "  Loss value: 0.038056\n",
      "  Predicted classes: tensor([1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "[DEBUG] Training batch 2:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-8.7824, 7.8154]\n",
      "  Loss value: 0.181406\n",
      "  Predicted classes: tensor([0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "[DEBUG] Training epoch 2:\n",
      "  Total loss: 6.841878\n",
      "  Num batches: 40\n",
      "  Average loss: 0.171047\n",
      "[DEBUG] Validation batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-9.6413, 8.7221]\n",
      "  Loss value: 0.077196\n",
      "  Predicted classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "[DEBUG] Validation epoch 2:\n",
      "  Total loss: 1.933000\n",
      "  Num batches: 10\n",
      "  Average loss: 0.193300\n",
      "Saved best model with validation loss: 0.1933\n",
      "Epoch 3/100:\n",
      "  Train Loss: 0.1710\n",
      "  Val Loss: 0.1933\n",
      "  Learning Rate: 0.000500\n",
      "  Best Val Loss: 0.1933\n",
      "  Early Stop Counter: 3/15\n",
      "\n",
      "[DEBUG] Training batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-8.2409, 7.2776]\n",
      "  Loss value: 0.149688\n",
      "  Predicted classes: tensor([1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "[DEBUG] Training batch 1:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-6.8807, 6.0097]\n",
      "  Loss value: 0.132256\n",
      "  Predicted classes: tensor([1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "[DEBUG] Training batch 2:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-8.0494, 7.9257]\n",
      "  Loss value: 0.046899\n",
      "  Predicted classes: tensor([0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "[DEBUG] Training epoch 3:\n",
      "  Total loss: 3.565186\n",
      "  Num batches: 40\n",
      "  Average loss: 0.089130\n",
      "[DEBUG] Validation batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-6.5255, 6.9518]\n",
      "  Loss value: 0.012413\n",
      "  Predicted classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "[DEBUG] Validation epoch 3:\n",
      "  Total loss: 3.442239\n",
      "  Num batches: 10\n",
      "  Average loss: 0.344224\n",
      "Epoch 4/100:\n",
      "  Train Loss: 0.0891\n",
      "  Val Loss: 0.3442\n",
      "  Learning Rate: 0.000500\n",
      "  Best Val Loss: 0.1933\n",
      "  Early Stop Counter: 4/15\n",
      "\n",
      "[DEBUG] Training batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-8.5881, 8.3337]\n",
      "  Loss value: 0.012405\n",
      "  Predicted classes: tensor([0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0], device='cuda:0')\n",
      "[DEBUG] Training batch 1:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-6.1805, 6.7342]\n",
      "  Loss value: 0.006981\n",
      "  Predicted classes: tensor([0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "[DEBUG] Training batch 2:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-6.7717, 7.7734]\n",
      "  Loss value: 0.013121\n",
      "  Predicted classes: tensor([1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "[DEBUG] Training epoch 4:\n",
      "  Total loss: 3.389287\n",
      "  Num batches: 40\n",
      "  Average loss: 0.084732\n",
      "[DEBUG] Validation batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-9.2511, 8.4605]\n",
      "  Loss value: 0.009510\n",
      "  Predicted classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "[DEBUG] Validation epoch 4:\n",
      "  Total loss: 3.818230\n",
      "  Num batches: 10\n",
      "  Average loss: 0.381823\n",
      "Epoch 5/100:\n",
      "  Train Loss: 0.0847\n",
      "  Val Loss: 0.3818\n",
      "  Learning Rate: 0.000500\n",
      "  Best Val Loss: 0.1933\n",
      "  Early Stop Counter: 5/15\n",
      "\n",
      "[DEBUG] Training batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-9.6800, 9.5562]\n",
      "  Loss value: 0.012252\n",
      "  Predicted classes: tensor([1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "[DEBUG] Training batch 1:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-9.0246, 8.3789]\n",
      "  Loss value: 0.235251\n",
      "  Predicted classes: tensor([1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "[DEBUG] Training batch 2:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-9.0369, 8.5613]\n",
      "  Loss value: 0.288469\n",
      "  Predicted classes: tensor([0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "[DEBUG] Training epoch 5:\n",
      "  Total loss: 2.712732\n",
      "  Num batches: 40\n",
      "  Average loss: 0.067818\n",
      "[DEBUG] Validation batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-11.0240, 12.0180]\n",
      "  Loss value: 0.000128\n",
      "  Predicted classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "[DEBUG] Validation epoch 5:\n",
      "  Total loss: 2.827486\n",
      "  Num batches: 10\n",
      "  Average loss: 0.282749\n",
      "Epoch 6/100:\n",
      "  Train Loss: 0.0678\n",
      "  Val Loss: 0.2827\n",
      "  Learning Rate: 0.000500\n",
      "  Best Val Loss: 0.1933\n",
      "  Early Stop Counter: 6/15\n",
      "\n",
      "[DEBUG] Training batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-7.1943, 7.6715]\n",
      "  Loss value: 0.003787\n",
      "  Predicted classes: tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "[DEBUG] Training batch 1:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-8.4098, 8.3190]\n",
      "  Loss value: 0.010431\n",
      "  Predicted classes: tensor([0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "[DEBUG] Training batch 2:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-7.6187, 10.0814]\n",
      "  Loss value: 0.115258\n",
      "  Predicted classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "[DEBUG] Training epoch 6:\n",
      "  Total loss: 1.634380\n",
      "  Num batches: 40\n",
      "  Average loss: 0.040860\n",
      "[DEBUG] Validation batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-7.0086, 6.8571]\n",
      "  Loss value: 0.002124\n",
      "  Predicted classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "[DEBUG] Validation epoch 6:\n",
      "  Total loss: 2.435877\n",
      "  Num batches: 10\n",
      "  Average loss: 0.243588\n",
      "Epoch 7/100:\n",
      "  Train Loss: 0.0409\n",
      "  Val Loss: 0.2436\n",
      "  Learning Rate: 0.000500\n",
      "  Best Val Loss: 0.1933\n",
      "  Early Stop Counter: 7/15\n",
      "\n",
      "[DEBUG] Training batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-8.4280, 8.2530]\n",
      "  Loss value: 0.011886\n",
      "  Predicted classes: tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "[DEBUG] Training batch 1:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-10.6393, 9.8265]\n",
      "  Loss value: 0.006587\n",
      "  Predicted classes: tensor([1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "[DEBUG] Training batch 2:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-9.3217, 9.4770]\n",
      "  Loss value: 0.022538\n",
      "  Predicted classes: tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "[DEBUG] Training epoch 7:\n",
      "  Total loss: 2.463446\n",
      "  Num batches: 40\n",
      "  Average loss: 0.061586\n",
      "[DEBUG] Validation batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-11.1382, 10.3286]\n",
      "  Loss value: 0.001071\n",
      "  Predicted classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "[DEBUG] Validation epoch 7:\n",
      "  Total loss: 2.103059\n",
      "  Num batches: 10\n",
      "  Average loss: 0.210306\n",
      "Epoch 8/100:\n",
      "  Train Loss: 0.0616\n",
      "  Val Loss: 0.2103\n",
      "  Learning Rate: 0.000500\n",
      "  Best Val Loss: 0.1933\n",
      "  Early Stop Counter: 8/15\n",
      "\n",
      "[DEBUG] Training batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-10.6676, 9.1229]\n",
      "  Loss value: 0.004836\n",
      "  Predicted classes: tensor([1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "[DEBUG] Training batch 1:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-8.4956, 8.2344]\n",
      "  Loss value: 0.012078\n",
      "  Predicted classes: tensor([1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "[DEBUG] Training batch 2:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-9.0482, 9.1567]\n",
      "  Loss value: 0.005832\n",
      "  Predicted classes: tensor([0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "[DEBUG] Training epoch 8:\n",
      "  Total loss: 1.771046\n",
      "  Num batches: 40\n",
      "  Average loss: 0.044276\n",
      "[DEBUG] Validation batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-9.8466, 9.3872]\n",
      "  Loss value: 0.000288\n",
      "  Predicted classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "[DEBUG] Validation epoch 8:\n",
      "  Total loss: 3.706268\n",
      "  Num batches: 10\n",
      "  Average loss: 0.370627\n",
      "Epoch 9/100:\n",
      "  Train Loss: 0.0443\n",
      "  Val Loss: 0.3706\n",
      "  Learning Rate: 0.000500\n",
      "  Best Val Loss: 0.1933\n",
      "  Early Stop Counter: 9/15\n",
      "\n",
      "[DEBUG] Training batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-13.1270, 12.2024]\n",
      "  Loss value: 0.002960\n",
      "  Predicted classes: tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0], device='cuda:0')\n",
      "[DEBUG] Training batch 1:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-13.2836, 12.7600]\n",
      "  Loss value: 0.050292\n",
      "  Predicted classes: tensor([1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "[DEBUG] Training batch 2:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-15.5404, 14.7272]\n",
      "  Loss value: 0.050122\n",
      "  Predicted classes: tensor([0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "[DEBUG] Training epoch 9:\n",
      "  Total loss: 2.718191\n",
      "  Num batches: 40\n",
      "  Average loss: 0.067955\n",
      "[DEBUG] Validation batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-10.9899, 10.5057]\n",
      "  Loss value: 0.017335\n",
      "  Predicted classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "[DEBUG] Validation epoch 9:\n",
      "  Total loss: 2.684735\n",
      "  Num batches: 10\n",
      "  Average loss: 0.268473\n",
      "Epoch 10/100:\n",
      "  Train Loss: 0.0680\n",
      "  Val Loss: 0.2685\n",
      "  Learning Rate: 0.000500\n",
      "  Best Val Loss: 0.1933\n",
      "  Early Stop Counter: 10/15\n",
      "\n",
      "[DEBUG] Training batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-9.3799, 8.9495]\n",
      "  Loss value: 0.019541\n",
      "  Predicted classes: tensor([0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "[DEBUG] Training batch 1:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-10.3615, 10.3868]\n",
      "  Loss value: 0.037798\n",
      "  Predicted classes: tensor([0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "[DEBUG] Training batch 2:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-9.3875, 8.3953]\n",
      "  Loss value: 0.005550\n",
      "  Predicted classes: tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "[DEBUG] Training epoch 10:\n",
      "  Total loss: 2.674054\n",
      "  Num batches: 40\n",
      "  Average loss: 0.066851\n",
      "[DEBUG] Validation batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-11.7912, 11.2493]\n",
      "  Loss value: 0.010010\n",
      "  Predicted classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "[DEBUG] Validation epoch 10:\n",
      "  Total loss: 3.851900\n",
      "  Num batches: 10\n",
      "  Average loss: 0.385190\n",
      "Epoch 11/100:\n",
      "  Train Loss: 0.0669\n",
      "  Val Loss: 0.3852\n",
      "  Learning Rate: 0.000500\n",
      "  Best Val Loss: 0.1933\n",
      "  Early Stop Counter: 11/15\n",
      "\n",
      "[DEBUG] Training batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-9.9150, 9.6239]\n",
      "  Loss value: 0.156160\n",
      "  Predicted classes: tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "[DEBUG] Training batch 1:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-10.6805, 9.7717]\n",
      "  Loss value: 0.004719\n",
      "  Predicted classes: tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "[DEBUG] Training batch 2:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-9.9504, 11.0123]\n",
      "  Loss value: 0.029825\n",
      "  Predicted classes: tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "[DEBUG] Training epoch 11:\n",
      "  Total loss: 1.839824\n",
      "  Num batches: 40\n",
      "  Average loss: 0.045996\n",
      "[DEBUG] Validation batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-10.9249, 10.5448]\n",
      "  Loss value: 0.012447\n",
      "  Predicted classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "[DEBUG] Validation epoch 11:\n",
      "  Total loss: 4.595692\n",
      "  Num batches: 10\n",
      "  Average loss: 0.459569\n",
      "Epoch 12/100:\n",
      "  Train Loss: 0.0460\n",
      "  Val Loss: 0.4596\n",
      "  Learning Rate: 0.000500\n",
      "  Best Val Loss: 0.1933\n",
      "  Early Stop Counter: 12/15\n",
      "\n",
      "[DEBUG] Training batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-8.8621, 8.9763]\n",
      "  Loss value: 0.061693\n",
      "  Predicted classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "[DEBUG] Training batch 1:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-12.1805, 11.0379]\n",
      "  Loss value: 0.020931\n",
      "  Predicted classes: tensor([0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "[DEBUG] Training batch 2:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-10.5755, 9.9854]\n",
      "  Loss value: 0.021019\n",
      "  Predicted classes: tensor([1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "[DEBUG] Training epoch 12:\n",
      "  Total loss: 2.888047\n",
      "  Num batches: 40\n",
      "  Average loss: 0.072201\n",
      "[DEBUG] Validation batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-13.2541, 12.3401]\n",
      "  Loss value: 0.000574\n",
      "  Predicted classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "[DEBUG] Validation epoch 12:\n",
      "  Total loss: 6.042814\n",
      "  Num batches: 10\n",
      "  Average loss: 0.604281\n",
      "Epoch 13/100:\n",
      "  Train Loss: 0.0722\n",
      "  Val Loss: 0.6043\n",
      "  Learning Rate: 0.000500\n",
      "  Best Val Loss: 0.1933\n",
      "  Early Stop Counter: 13/15\n",
      "\n",
      "[DEBUG] Training batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-8.4877, 7.9146]\n",
      "  Loss value: 0.008515\n",
      "  Predicted classes: tensor([0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "[DEBUG] Training batch 1:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-12.4918, 11.8387]\n",
      "  Loss value: 0.072762\n",
      "  Predicted classes: tensor([0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1], device='cuda:0')\n",
      "[DEBUG] Training batch 2:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-12.3029, 12.1850]\n",
      "  Loss value: 0.020890\n",
      "  Predicted classes: tensor([0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "[DEBUG] Training epoch 13:\n",
      "  Total loss: 1.755695\n",
      "  Num batches: 40\n",
      "  Average loss: 0.043892\n",
      "[DEBUG] Validation batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-15.7941, 14.9180]\n",
      "  Loss value: 0.003586\n",
      "  Predicted classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "[DEBUG] Validation epoch 13:\n",
      "  Total loss: 1.618583\n",
      "  Num batches: 10\n",
      "  Average loss: 0.161858\n",
      "Saved best model with validation loss: 0.1619\n",
      "Epoch 14/100:\n",
      "  Train Loss: 0.0439\n",
      "  Val Loss: 0.1619\n",
      "  Learning Rate: 0.000500\n",
      "  Best Val Loss: 0.1619\n",
      "  Early Stop Counter: 14/15\n",
      "\n",
      "[DEBUG] Training batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-9.8374, 9.9958]\n",
      "  Loss value: 0.030927\n",
      "  Predicted classes: tensor([0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "[DEBUG] Training batch 1:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-10.9286, 10.2927]\n",
      "  Loss value: 0.002102\n",
      "  Predicted classes: tensor([0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "[DEBUG] Training batch 2:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-11.3001, 9.7528]\n",
      "  Loss value: 0.008692\n",
      "  Predicted classes: tensor([0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "[DEBUG] Training epoch 14:\n",
      "  Total loss: 2.524149\n",
      "  Num batches: 40\n",
      "  Average loss: 0.063104\n",
      "[DEBUG] Validation batch 0:\n",
      "  Images shape: torch.Size([16, 3, 160, 160])\n",
      "  Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "  Outputs shape: torch.Size([16, 2])\n",
      "  Outputs range: [-11.7215, 11.0185]\n",
      "  Loss value: 0.047301\n",
      "  Predicted classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "[DEBUG] Validation epoch 14:\n",
      "  Total loss: 2.744522\n",
      "  Num batches: 10\n",
      "  Average loss: 0.274452\n",
      "Epoch 15/100:\n",
      "  Train Loss: 0.0631\n",
      "  Val Loss: 0.2745\n",
      "  Learning Rate: 0.000250\n",
      "  Best Val Loss: 0.1619\n",
      "  Early Stop Counter: 15/15\n",
      "\n",
      "Early stopping triggered after 15 epochs!\n",
      "Best validation loss: 0.1619\n",
      "Training stopped early due to no improvement!\n",
      "Best validation loss: 0.1619\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training completed successfully!\n",
      "Best validation loss: 0.1619\n",
      "Model saved to: ./models\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Section 2: Model Selection and Training\n",
    "Lightweight face detection model optimized for real-time processing on Kaggle hardware\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "# from config import Config\n",
    "# from data_loader_utils import create_data_loaders\n",
    "\n",
    "# Utility function to load best learning rate if available\n",
    "def get_best_learning_rate():\n",
    "    best_lr_path = os.path.join(\"/kaggle/input/fd-02-hyperparam-tuning/output\", \"best_learning_rate.txt\")\n",
    "    if os.path.exists(best_lr_path):\n",
    "        try:\n",
    "            with open(best_lr_path, \"r\") as f:\n",
    "                lr = float(f.read().strip())\n",
    "                print(f\"[INFO] Using best learning rate from tuning: {lr}\")\n",
    "                return lr\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Could not read best learning rate: {e}. Using default.\")\n",
    "    print(f\"[INFO] Using default learning rate: {Config.LEARNING_RATE}\")\n",
    "    return Config.LEARNING_RATE\n",
    "\n",
    "def get_best_hyperparameters():\n",
    "    \"\"\"Load best hyperparameters from tuning results\"\"\"\n",
    "    best_params_path = os.path.join(\"/kaggle/input/fd-02-hyperparam-tuning/output\", \"best_hyperparameters.json\")\n",
    "    \n",
    "    if os.path.exists(best_params_path):\n",
    "        try:\n",
    "            with open(best_params_path, 'r') as f:\n",
    "                params = json.load(f)\n",
    "            print(f\"[INFO] Loaded best hyperparameters from {best_params_path}\")\n",
    "            return params\n",
    "        except Exception as e:\n",
    "            print(f\"[WARNING] Failed to load hyperparameters: {e}\")\n",
    "    \n",
    "    # Default hyperparameters (from sequential tuning approach)\n",
    "    print(\"[INFO] Using default hyperparameters\")\n",
    "    return {\n",
    "        'learning_rate': 1e-3,  # Default learning rate\n",
    "        'weight_decay': 1e-4,   # Default weight decay\n",
    "        'batch_size': 16,        # Fixed batch size\n",
    "        'scheduler_step_size': 15  # Fixed step size\n",
    "    }\n",
    "\n",
    "class FaceRecognitionModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Face recognition model for Davido vs Unknown classification\n",
    "    Uses MobileNetV2 backbone with a classification head\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=2, pretrained=True):\n",
    "        super().__init__()\n",
    "        if pretrained:\n",
    "            # Use pretrained weights\n",
    "            self.backbone = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1).features\n",
    "        else:\n",
    "            # Use random weights (no download)\n",
    "            self.backbone = models.mobilenet_v2(weights=None).features\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1280, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class ModelTrainer:\n",
    "    \"\"\"\n",
    "    Handles model training for face recognition (classification)\n",
    "    \"\"\"\n",
    "    def __init__(self, model, train_loader, val_loader):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        # Load best hyperparameters\n",
    "        best_params = get_best_hyperparameters()\n",
    "        \n",
    "        # Initialize optimizer and scheduler with best parameters\n",
    "        self.optimizer = optim.AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=best_params['learning_rate'],\n",
    "            weight_decay=best_params['weight_decay']\n",
    "        )\n",
    "        \n",
    "        self.scheduler = optim.lr_scheduler.StepLR(\n",
    "            self.optimizer,\n",
    "            step_size=best_params['scheduler_step_size'],\n",
    "            gamma=Config.SCHEDULER_GAMMA\n",
    "        )\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.writer = SummaryWriter(Config.LOGS_DIR)\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.best_val_loss = float('inf')\n",
    "        \n",
    "        # Early stopping parameters\n",
    "        self.patience = Config.EARLY_STOPPING_PATIENCE\n",
    "        self.min_delta = Config.EARLY_STOPPING_MIN_DELTA\n",
    "        self.counter = 0  # Counter for epochs without improvement\n",
    "        self.early_stop = False  # Flag to stop training\n",
    "        \n",
    "        # Debug model and loss function\n",
    "        print(f\"Model initialized on device: {self.device}\")\n",
    "        print(f\"Total parameters: {sum(p.numel() for p in self.model.parameters()):,}\")\n",
    "        print(f\"Learning rate: {best_params['learning_rate']:.6f}\")\n",
    "        print(f\"Weight decay: {best_params['weight_decay']:.6f}\")\n",
    "        print(f\"Loss function: {self.criterion}\")\n",
    "        print(f\"Early stopping patience: {self.patience}\")\n",
    "        print(f\"Early stopping min delta: {self.min_delta}\")\n",
    "        \n",
    "        # Test model with dummy input\n",
    "        dummy_input = torch.randn(1, 3, Config.IMAGE_SIZE[0], Config.IMAGE_SIZE[1]).to(self.device)\n",
    "        dummy_output = self.model(dummy_input)\n",
    "        print(f\"Model test - Input shape: {dummy_input.shape}\")\n",
    "        print(f\"Model test - Output shape: {dummy_output.shape}\")\n",
    "        print(f\"Model test - Output range: [{dummy_output.min().item():.4f}, {dummy_output.max().item():.4f}]\")\n",
    "        \n",
    "        # Test loss function\n",
    "        dummy_labels = torch.randint(0, Config.NUM_CLASSES, (1,)).to(self.device)\n",
    "        dummy_loss = self.criterion(dummy_output, dummy_labels)\n",
    "        print(f\"Loss test - Labels: {dummy_labels}\")\n",
    "        print(f\"Loss test - Loss value: {dummy_loss.item():.6f}\")\n",
    "    \n",
    "    def check_early_stopping(self, val_loss):\n",
    "        \"\"\"Check if training should stop early\"\"\"\n",
    "        if val_loss < self.best_val_loss - self.min_delta:\n",
    "            self.best_val_loss = val_loss\n",
    "            self.counter = 0\n",
    "            return False  # Continue training\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True  # Stop training\n",
    "            return False  # Continue training\n",
    "    def train_epoch(self, epoch):\n",
    "        \"\"\"Train for one epoch\"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        # Check if train_loader is empty\n",
    "        if len(self.train_loader) == 0:\n",
    "            print(\"[ERROR] Training loader is empty!\")\n",
    "            return 0.0\n",
    "        \n",
    "        for batch_idx, batch in enumerate(self.train_loader):\n",
    "            # Handle dictionary format from dataset\n",
    "            if isinstance(batch, dict):\n",
    "                images = batch['image'].to(self.device)\n",
    "                labels = batch['label'].to(self.device)\n",
    "            else:\n",
    "                # Handle tuple format (images, labels)\n",
    "                images, labels = batch\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(images)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # Debug information for first few batches\n",
    "            if batch_idx < 3:  # Print first 3 batches info\n",
    "                print(f\"[DEBUG] Training batch {batch_idx}:\")\n",
    "                print(f\"  Images shape: {images.shape}\")\n",
    "                print(f\"  Labels: {labels}\")\n",
    "                print(f\"  Outputs shape: {outputs.shape}\")\n",
    "                print(f\"  Outputs range: [{outputs.min().item():.4f}, {outputs.max().item():.4f}]\")\n",
    "                print(f\"  Loss value: {loss.item():.6f}\")\n",
    "                print(f\"  Predicted classes: {torch.argmax(outputs, dim=1)}\")\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                self.writer.add_scalar('Train/Loss', loss.item(), epoch * len(self.train_loader) + batch_idx)\n",
    "        \n",
    "        # Prevent division by zero\n",
    "        if num_batches == 0:\n",
    "            print(\"[ERROR] No batches processed in training epoch!\")\n",
    "            return 0.0\n",
    "            \n",
    "        avg_loss = total_loss / num_batches\n",
    "        self.train_losses.append(avg_loss)\n",
    "        \n",
    "        # Debug final training loss\n",
    "        print(f\"[DEBUG] Training epoch {epoch}:\")\n",
    "        print(f\"  Total loss: {total_loss:.6f}\")\n",
    "        print(f\"  Num batches: {num_batches}\")\n",
    "        print(f\"  Average loss: {avg_loss:.6f}\")\n",
    "        \n",
    "        return avg_loss\n",
    "    def validate_epoch(self, epoch):\n",
    "        \"\"\"Validate for one epoch\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        # Check if val_loader is empty\n",
    "        if len(self.val_loader) == 0:\n",
    "            print(\"[ERROR] Validation loader is empty!\")\n",
    "            return 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(self.val_loader):\n",
    "                # Handle dictionary format from dataset\n",
    "                if isinstance(batch, dict):\n",
    "                    images = batch['image'].to(self.device)\n",
    "                    labels = batch['label'].to(self.device)\n",
    "                else:\n",
    "                    # Handle tuple format (images, labels)\n",
    "                    images, labels = batch\n",
    "                    images = images.to(self.device)\n",
    "                    labels = labels.to(self.device)\n",
    "                \n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                \n",
    "                # Debug information\n",
    "                if batch_idx == 0:  # Print first batch info\n",
    "                    print(f\"[DEBUG] Validation batch {batch_idx}:\")\n",
    "                    print(f\"  Images shape: {images.shape}\")\n",
    "                    print(f\"  Labels: {labels}\")\n",
    "                    print(f\"  Outputs shape: {outputs.shape}\")\n",
    "                    print(f\"  Outputs range: [{outputs.min().item():.4f}, {outputs.max().item():.4f}]\")\n",
    "                    print(f\"  Loss value: {loss.item():.6f}\")\n",
    "                    print(f\"  Predicted classes: {torch.argmax(outputs, dim=1)}\")\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                num_batches += 1\n",
    "                \n",
    "                if batch_idx % 10 == 0:\n",
    "                    self.writer.add_scalar('Val/Loss', loss.item(), epoch * len(self.val_loader) + batch_idx)\n",
    "        \n",
    "        # Prevent division by zero\n",
    "        if num_batches == 0:\n",
    "            print(\"[ERROR] No batches processed in validation epoch!\")\n",
    "            return 0.0\n",
    "            \n",
    "        avg_loss = total_loss / num_batches\n",
    "        self.val_losses.append(avg_loss)\n",
    "        \n",
    "        # Debug final validation loss\n",
    "        print(f\"[DEBUG] Validation epoch {epoch}:\")\n",
    "        print(f\"  Total loss: {total_loss:.6f}\")\n",
    "        print(f\"  Num batches: {num_batches}\")\n",
    "        print(f\"  Average loss: {avg_loss:.6f}\")\n",
    "        \n",
    "        return avg_loss\n",
    "    def save_checkpoint(self, epoch, is_best=False):\n",
    "        # Ensure models directory exists\n",
    "        os.makedirs(Config.MODELS_DIR, exist_ok=True)\n",
    "        \n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "            'train_losses': self.train_losses,\n",
    "            'val_losses': self.val_losses,\n",
    "            'best_val_loss': self.best_val_loss\n",
    "        }\n",
    "        checkpoint_path = os.path.join(Config.MODELS_DIR, f'checkpoint_epoch_{epoch}.pt')\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        if is_best:\n",
    "            best_path = os.path.join(Config.MODELS_DIR, 'best_model.pt')\n",
    "            torch.save(checkpoint, best_path)\n",
    "            print(f\"Saved best model with validation loss: {self.best_val_loss:.4f}\")\n",
    "    def train(self):\n",
    "        print(\"Starting training...\")\n",
    "        print(f\"Training for {Config.EPOCHS} epochs (with early stopping)\")\n",
    "        print(f\"Learning rate: {self.optimizer.param_groups[0]['lr']}\")\n",
    "        print(f\"Batch size: {Config.BATCH_SIZE}\")\n",
    "        print(f\"Early stopping patience: {self.patience}\")\n",
    "        \n",
    "        for epoch in range(Config.EPOCHS):\n",
    "            train_loss = self.train_epoch(epoch)\n",
    "            val_loss = self.validate_epoch(epoch)\n",
    "            self.scheduler.step()\n",
    "            \n",
    "            # Check for best model\n",
    "            is_best = val_loss < self.best_val_loss\n",
    "            if is_best:\n",
    "                self.best_val_loss = val_loss\n",
    "            \n",
    "            # Check early stopping\n",
    "            should_stop = self.check_early_stopping(val_loss)\n",
    "            \n",
    "            # Save checkpoint periodically or when best\n",
    "            if (epoch + 1) % 5 == 0 or is_best:\n",
    "                self.save_checkpoint(epoch, is_best)\n",
    "            \n",
    "            print(f'Epoch {epoch+1}/{Config.EPOCHS}:')\n",
    "            print(f'  Train Loss: {train_loss:.4f}')\n",
    "            print(f'  Val Loss: {val_loss:.4f}')\n",
    "            print(f'  Learning Rate: {self.scheduler.get_last_lr()[0]:.6f}')\n",
    "            print(f'  Best Val Loss: {self.best_val_loss:.4f}')\n",
    "            print(f'  Early Stop Counter: {self.counter}/{self.patience}')\n",
    "            \n",
    "            if should_stop:\n",
    "                print(f'\\nEarly stopping triggered after {epoch+1} epochs!')\n",
    "                print(f'Best validation loss: {self.best_val_loss:.4f}')\n",
    "                break\n",
    "            \n",
    "            print()\n",
    "        \n",
    "        # Save final checkpoint\n",
    "        self.save_checkpoint(epoch, False)\n",
    "        self.writer.close()\n",
    "        \n",
    "        if should_stop:\n",
    "            print(\"Training stopped early due to no improvement!\")\n",
    "        else:\n",
    "            print(\"Training completed for all epochs!\")\n",
    "        \n",
    "        print(f\"Best validation loss: {self.best_val_loss:.4f}\")\n",
    "        return self.model\n",
    "    def plot_training_history(self):\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(self.train_losses, label='Train Loss')\n",
    "        plt.plot(self.val_losses, label='Val Loss')\n",
    "        plt.title('Training History')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(Config.OUTPUT_DIR, 'training_history.png'))\n",
    "        plt.show()\n",
    "\n",
    "def main():\n",
    "    print(\"=== Section 2: Model Selection and Training ===\")\n",
    "    \n",
    "    # Create necessary directories\n",
    "    Config.create_directories()\n",
    "    \n",
    "    train_loader, val_loader = create_data_loaders()\n",
    "    if train_loader is None or val_loader is None:\n",
    "        print(\"Failed to load data. Please check data preparation.\")\n",
    "        return\n",
    "    model = FaceRecognitionModel(num_classes=Config.NUM_CLASSES, pretrained=Config.PRETRAINED)\n",
    "    trainer = ModelTrainer(model, train_loader, val_loader)\n",
    "    trained_model = trainer.train()\n",
    "    trainer.plot_training_history()\n",
    "    print(\"Model training completed successfully!\")\n",
    "    print(f\"Best validation loss: {trainer.best_val_loss:.4f}\")\n",
    "    print(f\"Model saved to: {Config.MODELS_DIR}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7961995,
     "sourceId": 12605156,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 253035811,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 253205525,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 215.394313,
   "end_time": "2025-07-29T22:37:28.830935",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-29T22:33:53.436622",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
