{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":20270,"databundleVersionId":1222630,"sourceType":"competition"}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!pip install segmentation-models-pytorch albumentations","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:10:54.472969Z","iopub.execute_input":"2025-04-20T23:10:54.473617Z","iopub.status.idle":"2025-04-20T23:10:54.477249Z","shell.execute_reply.started":"2025-04-20T23:10:54.473593Z","shell.execute_reply":"2025-04-20T23:10:54.476245Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"#!pip install -U Albumentations","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:10:54.516505Z","iopub.execute_input":"2025-04-20T23:10:54.516733Z","iopub.status.idle":"2025-04-20T23:10:54.519988Z","shell.execute_reply.started":"2025-04-20T23:10:54.516717Z","shell.execute_reply":"2025-04-20T23:10:54.519224Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nimport torch\nimport sys\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport segmentation_models_pytorch as smp\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport pandas as pd\nimport numpy as np\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:10:54.556747Z","iopub.execute_input":"2025-04-20T23:10:54.556968Z","iopub.status.idle":"2025-04-20T23:10:54.561577Z","shell.execute_reply.started":"2025-04-20T23:10:54.556953Z","shell.execute_reply":"2025-04-20T23:10:54.560883Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"print(\"Platform:\", sys.platform)\nprint(\"Python version:\", sys.version)\nprint(\"---------------\")\nprint(\"CV2 version : \", cv2.__version__)\nprint(\"torch version : \", torch.__version__)\nprint(\"torchvision version : \", torchvision.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:10:54.595242Z","iopub.execute_input":"2025-04-20T23:10:54.595510Z","iopub.status.idle":"2025-04-20T23:10:54.599993Z","shell.execute_reply.started":"2025-04-20T23:10:54.595484Z","shell.execute_reply":"2025-04-20T23:10:54.599275Z"}},"outputs":[{"name":"stdout","text":"Platform: linux\nPython version: 3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]\n---------------\nCV2 version :  4.11.0\ntorch version :  2.5.1+cu124\ntorchvision version :  0.20.1+cu124\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using {device} device.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:10:54.601255Z","iopub.execute_input":"2025-04-20T23:10:54.601600Z","iopub.status.idle":"2025-04-20T23:10:54.611893Z","shell.execute_reply.started":"2025-04-20T23:10:54.601585Z","shell.execute_reply":"2025-04-20T23:10:54.611195Z"}},"outputs":[{"name":"stdout","text":"Using cuda device.\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"#!rm /kaggle/working/\"multimodal_unet.py\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:10:54.612539Z","iopub.execute_input":"2025-04-20T23:10:54.612804Z","iopub.status.idle":"2025-04-20T23:10:54.626650Z","shell.execute_reply.started":"2025-04-20T23:10:54.612782Z","shell.execute_reply":"2025-04-20T23:10:54.625750Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"# %%writefile medical_datasets.py\n# import cv2\n# import numpy as np\n# import os\n# from torch.utils.data import Dataset\n\n# class MedicalDataset(Dataset):\n#     def __init__(self, df, image_dir, transform=None):\n#         self.df = df\n#         self.image_dir = image_dir\n#         self.transform = transform\n    \n#     def __len__(self):\n#         return len(self.df)\n    \n#     def __getitem__(self, idx):\n#         img_name = self.df.iloc[idx][\"image_name\"]\n#         img_path = os.path.join(self.image_dir, f\"{img_name}.jpg\")\n        \n#         image = cv2.imread(img_path)\n#         if image is None:\n#             print(f\"Warning: Failed to load image {img_path}. Using blank image.\")\n#             image = np.zeros((256, 256, 3), dtype=np.uint8)\n#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n#         label = self.df.iloc[idx][\"target\"].astype(np.float32)  # Binary classification label\n#         metadata = self.df.iloc[idx][[\"age_approx\", \"sex\"]].values.astype(np.float32)\n        \n#         if self.transform:\n#             augmented = self.transform(image=image)\n#             image = augmented[\"image\"]\n        \n#         return image, label, metadata","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:10:54.628059Z","iopub.execute_input":"2025-04-20T23:10:54.628249Z","iopub.status.idle":"2025-04-20T23:10:54.637667Z","shell.execute_reply.started":"2025-04-20T23:10:54.628234Z","shell.execute_reply":"2025-04-20T23:10:54.636920Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"# %%writefile multimodal_class.py\n# import torch\n# import torch.nn as nn\n# import segmentation_models_pytorch as smp\n\n# class MultimodalClassifier(nn.Module):\n#     def __init__(self, encoder_name=\"resnet50\", encoder_weights=\"imagenet\", metadata_size=2):\n#         super(MultimodalClassifier, self).__init__()\n#         self.encoder = smp.Unet(encoder_name=encoder_name, encoder_weights=encoder_weights, in_channels=3, classes=1).encoder\n#         self.pool = nn.AdaptiveAvgPool2d(1)\n#         self.metadata_mlp = nn.Sequential(\n#             nn.Linear(metadata_size, 64), nn.ReLU(),\n#             nn.Linear(64, 128), nn.ReLU()\n#         )\n#         self.fc = nn.Linear(128 + 2048, 1)  # Adjust based on encoder output size\n    \n#     def forward(self, x, metadata):\n#         features = self.encoder(x)[-1]\n#         features = self.pool(features).view(features.size(0), -1)\n#         metadata_features = self.metadata_mlp(metadata)\n#         combined = torch.cat([features, metadata_features], dim=1)\n#         return self.fc(combined)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:10:54.638789Z","iopub.execute_input":"2025-04-20T23:10:54.639092Z","iopub.status.idle":"2025-04-20T23:10:54.654505Z","shell.execute_reply.started":"2025-04-20T23:10:54.639076Z","shell.execute_reply":"2025-04-20T23:10:54.653877Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"data_dir = \"/kaggle/input/siim-isic-melanoma-classification\"\nimage_dir = os.path.join(data_dir, \"jpeg/train\")\nmask_dir = None\ncsv_path = os.path.join(data_dir, \"train.csv\")\ndf = pd.read_csv(csv_path)\nprint(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:10:54.655058Z","iopub.execute_input":"2025-04-20T23:10:54.655238Z","iopub.status.idle":"2025-04-20T23:10:54.779450Z","shell.execute_reply.started":"2025-04-20T23:10:54.655225Z","shell.execute_reply":"2025-04-20T23:10:54.778752Z"}},"outputs":[{"name":"stdout","text":"     image_name  patient_id     sex  age_approx anatom_site_general_challenge  \\\n0  ISIC_2637011  IP_7279968    male        45.0                     head/neck   \n1  ISIC_0015719  IP_3075186  female        45.0               upper extremity   \n2  ISIC_0052212  IP_2842074  female        50.0               lower extremity   \n3  ISIC_0068279  IP_6890425  female        45.0                     head/neck   \n4  ISIC_0074268  IP_8723313  female        55.0               upper extremity   \n\n  diagnosis benign_malignant  target  \n0   unknown           benign       0  \n1   unknown           benign       0  \n2     nevus           benign       0  \n3   unknown           benign       0  \n4   unknown           benign       0  \n","output_type":"stream"}],"execution_count":46},{"cell_type":"markdown","source":"# Preprocessing the Metadata\nNeeds to encode the categorical `sex` vars and normalize the numerical `age_approx` col.","metadata":{}},{"cell_type":"code","source":"df[\"sex\"] = df[\"sex\"].map({\"male\": 0, \"female\": 1}).fillna(0)\ndf[\"age_approx\"] = (df[\"age_approx\"] - df[\"age_approx\"].mean()) / df[\"age_approx\"].std()\ndf = df.fillna(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:10:54.781158Z","iopub.execute_input":"2025-04-20T23:10:54.781402Z","iopub.status.idle":"2025-04-20T23:10:54.811994Z","shell.execute_reply.started":"2025-04-20T23:10:54.781383Z","shell.execute_reply":"2025-04-20T23:10:54.811325Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"print(\"============= INFORMATION ===============\")\ndf.iloc[:, 2:4].info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:10:54.812850Z","iopub.execute_input":"2025-04-20T23:10:54.813127Z","iopub.status.idle":"2025-04-20T23:10:54.845630Z","shell.execute_reply.started":"2025-04-20T23:10:54.813109Z","shell.execute_reply":"2025-04-20T23:10:54.844767Z"}},"outputs":[{"name":"stdout","text":"============= INFORMATION ===============\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 33126 entries, 0 to 33125\nData columns (total 2 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   sex         33126 non-null  float64\n 1   age_approx  33126 non-null  float64\ndtypes: float64(2)\nmemory usage: 517.7 KB\n","output_type":"stream"}],"execution_count":48},{"cell_type":"markdown","source":"## Dataset Splitting\nDetermiistic Splitting: Into 80% training, 20% validation","metadata":{}},{"cell_type":"code","source":"g = torch.Generator().manual_seed(42)\ntrain_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\nprint(f\"Train: {len(train_df)}, Val: {len(val_df)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:10:54.846533Z","iopub.execute_input":"2025-04-20T23:10:54.847610Z","iopub.status.idle":"2025-04-20T23:10:54.858412Z","shell.execute_reply.started":"2025-04-20T23:10:54.847584Z","shell.execute_reply":"2025-04-20T23:10:54.857809Z"}},"outputs":[{"name":"stdout","text":"Train: 26500, Val: 6626\n","output_type":"stream"}],"execution_count":49},{"cell_type":"markdown","source":"## Define Data Augmentation\n- Albumentations","metadata":{}},{"cell_type":"code","source":"image_height, image_width = 128, 128\n\ntrain_transform = A.Compose([\n    A.Resize(image_height, image_width),\n    A.HorizontalFlip(p=0.5),\n    A.RandomRotate90(p=0.5),\n    A.RandomBrightnessContrast(p=0.2),\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    ToTensorV2()\n])\n\nval_transform = A.Compose([\n    A.Resize(image_height, image_width),\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    ToTensorV2()\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:10:54.859069Z","iopub.execute_input":"2025-04-20T23:10:54.859302Z","iopub.status.idle":"2025-04-20T23:10:54.877664Z","shell.execute_reply.started":"2025-04-20T23:10:54.859286Z","shell.execute_reply":"2025-04-20T23:10:54.876824Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"from medical_datasets import MedicalDataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:10:54.878535Z","iopub.execute_input":"2025-04-20T23:10:54.878768Z","iopub.status.idle":"2025-04-20T23:10:54.886862Z","shell.execute_reply.started":"2025-04-20T23:10:54.878754Z","shell.execute_reply":"2025-04-20T23:10:54.886267Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"MedicalDataset?","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:10:54.887614Z","iopub.execute_input":"2025-04-20T23:10:54.887826Z","iopub.status.idle":"2025-04-20T23:10:54.900078Z","shell.execute_reply.started":"2025-04-20T23:10:54.887803Z","shell.execute_reply":"2025-04-20T23:10:54.899403Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[0;31mInit signature:\u001b[0m \u001b[0mMedicalDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mDocstring:\u001b[0m     \nAn abstract class representing a :class:`Dataset`.\n\nAll datasets that represent a map from keys to data samples should subclass\nit. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\ndata sample for a given key. Subclasses could also optionally overwrite\n:meth:`__len__`, which is expected to return the size of the dataset by many\n:class:`~torch.utils.data.Sampler` implementations and the default options\nof :class:`~torch.utils.data.DataLoader`. Subclasses could also\noptionally implement :meth:`__getitems__`, for speedup batched samples\nloading. This method accepts list of indices of samples of batch and returns\nlist of samples.\n\n.. note::\n  :class:`~torch.utils.data.DataLoader` by default constructs an index\n  sampler that yields integral indices.  To make it work with a map-style\n  dataset with non-integral indices/keys, a custom sampler must be provided.\n\u001b[0;31mFile:\u001b[0m           /kaggle/working/medical_datasets.py\n\u001b[0;31mType:\u001b[0m           type\n\u001b[0;31mSubclasses:\u001b[0m     \n"},"metadata":{}}],"execution_count":52},{"cell_type":"markdown","source":"## Creating DataLoaders\nInitializing datasets and DataLoaders with a batch_size of 16.","metadata":{}},{"cell_type":"code","source":"batch_size = 16\ntrain_dataset = MedicalDataset(train_df, image_dir,transform=train_transform)\nval_dataset = MedicalDataset(val_df, image_dir, transform=val_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, generator=g)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:10:54.902004Z","iopub.execute_input":"2025-04-20T23:10:54.902282Z","iopub.status.idle":"2025-04-20T23:10:54.912430Z","shell.execute_reply.started":"2025-04-20T23:10:54.902260Z","shell.execute_reply":"2025-04-20T23:10:54.911713Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"try:\n    for images, masks, metadata in train_loader:\n        print(f\"Images shape: {images.shape}\")  # Expected: [16, 3, 256, 256]\n        print(f\"Masks shape: {masks.shape}\")   # Expected: [16, 1, 256, 256]\n        print(f\"Metadata shape: {metadata.shape}\")  # Expected: [16, 2]\n        break\nexcept Exception as e:\n    print(f\"DataLoader error: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:10:54.913078Z","iopub.execute_input":"2025-04-20T23:10:54.913235Z","iopub.status.idle":"2025-04-20T23:10:59.581243Z","shell.execute_reply.started":"2025-04-20T23:10:54.913223Z","shell.execute_reply":"2025-04-20T23:10:59.580299Z"}},"outputs":[{"name":"stdout","text":"Images shape: torch.Size([16, 3, 128, 128])\nMasks shape: torch.Size([16])\nMetadata shape: torch.Size([16, 2])\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"# missing_files = []\n# for img_name in train_df[\"image_name\"]:\n#     img_path = os.path.join(image_dir, f\"{img_name}.jpg\")\n#     if not os.path.exists(img_path):\n#         missing_files.append(img_path)\n# if missing_files:\n#     print(f\"Missing {len(missing_files)} files, e.g., {missing_files[:5]}\")\n# else:\n#     print(\"All image files found.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:10:59.582490Z","iopub.execute_input":"2025-04-20T23:10:59.583357Z","iopub.status.idle":"2025-04-20T23:10:59.586888Z","shell.execute_reply.started":"2025-04-20T23:10:59.583331Z","shell.execute_reply":"2025-04-20T23:10:59.586214Z"}},"outputs":[],"execution_count":55},{"cell_type":"markdown","source":"## Defining Multimodal U-Net Model\n- Define the model\n- Freeze Encoder Weights of `ResNet50` TL\n- Loss definition (`Dice` + `BCE`)\n- Optimizer Definition (`Adam`)\n- Callbacks (`lr` scheduling, early-stopping, and checkpointing)","metadata":{}},{"cell_type":"code","source":"# point 1\nfrom multimodal_class import MultimodalClassifier","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:10:59.587716Z","iopub.execute_input":"2025-04-20T23:10:59.588027Z","iopub.status.idle":"2025-04-20T23:10:59.602152Z","shell.execute_reply.started":"2025-04-20T23:10:59.588005Z","shell.execute_reply":"2025-04-20T23:10:59.601419Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"model = MultimodalClassifier().to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:10:59.602852Z","iopub.execute_input":"2025-04-20T23:10:59.603071Z","iopub.status.idle":"2025-04-20T23:11:00.751583Z","shell.execute_reply.started":"2025-04-20T23:10:59.603055Z","shell.execute_reply":"2025-04-20T23:11:00.751030Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"# Point 2\nfor param in model.encoder.parameters():\n    param.requires_grad = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:11:00.752333Z","iopub.execute_input":"2025-04-20T23:11:00.752569Z","iopub.status.idle":"2025-04-20T23:11:00.756723Z","shell.execute_reply.started":"2025-04-20T23:11:00.752553Z","shell.execute_reply":"2025-04-20T23:11:00.755994Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"import pandas as pd\n\n# Load train.csv to calculate class imbalance\n\nnum_negative = len(df[df[\"target\"] == 0])\nnum_positive = len(df[df[\"target\"] == 1])\npos_weight_value = num_negative / num_positive if num_positive > 0 else 10.0  # Fallback to 10.0 if no positives\nprint(f\"Negative samples: {num_negative}, Positive samples: {num_positive}, pos_weight: {pos_weight_value:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:11:00.757535Z","iopub.execute_input":"2025-04-20T23:11:00.757751Z","iopub.status.idle":"2025-04-20T23:11:00.775649Z","shell.execute_reply.started":"2025-04-20T23:11:00.757736Z","shell.execute_reply":"2025-04-20T23:11:00.774742Z"}},"outputs":[{"name":"stdout","text":"Negative samples: 32542, Positive samples: 584, pos_weight: 55.72\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"# Point 3\n\n# Define loss with class imbalance correction\npos_weight = torch.tensor([pos_weight_value]).to(device)\nloss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n\noptimizer = optim.AdamW(model.parameters(), lr=1e-4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:11:00.776528Z","iopub.execute_input":"2025-04-20T23:11:00.776790Z","iopub.status.idle":"2025-04-20T23:11:00.782103Z","shell.execute_reply.started":"2025-04-20T23:11:00.776762Z","shell.execute_reply":"2025-04-20T23:11:00.781428Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"optimizer = optim.AdamW(model.parameters(), lr=1e-4)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=3)\ncheckpoint_path = \"/kaggle/working/best_model.pth\"\nearly_stopping_patience = 5\nbest_val_loss = float(\"inf\")\npatience_counter = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:11:00.782699Z","iopub.execute_input":"2025-04-20T23:11:00.782867Z","iopub.status.idle":"2025-04-20T23:11:00.795894Z","shell.execute_reply.started":"2025-04-20T23:11:00.782855Z","shell.execute_reply":"2025-04-20T23:11:00.795230Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"# # Load checkpoint\n# checkpoint_path = \"/kaggle/working/best_model.pth\"\n# if os.path.exists(checkpoint_path):\n#     checkpoint = torch.load(checkpoint_path, map_location=device)\n#     model.load_state_dict(checkpoint[\"model_state_dict\"])\n#     optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n#     start_epoch = checkpoint[\"epoch\"] + 1  # Resume from next epoch\n#     best_val_loss = checkpoint[\"val_loss\"]\n#     print(f\"Resuming training from epoch {start_epoch}, best val loss: {best_val_loss:.4f}\")\n# else:\n#     print(f\"Checkpoint not found at {checkpoint_path}. Starting from scratch.\")\n#     start_epoch = 0\n#     best_val_loss = float(\"inf\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:11:00.796707Z","iopub.execute_input":"2025-04-20T23:11:00.796983Z","iopub.status.idle":"2025-04-20T23:11:00.807579Z","shell.execute_reply.started":"2025-04-20T23:11:00.796961Z","shell.execute_reply":"2025-04-20T23:11:00.806849Z"}},"outputs":[],"execution_count":62},{"cell_type":"markdown","source":"## Training the Model\n- Point1: Train for one epoch for defining the training function\n- Point2: Train for 20 epochs first to see if there is a call back following worse loss","metadata":{}},{"cell_type":"code","source":"# Point 1\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nimport numpy as np\n\ndef train_one_epoch(model, loader, loss_fn, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    all_preds, all_labels = [], []\n    \n    for images, labels, metadata in tqdm(loader):\n        images, labels, metadata = images.to(device), labels.to(device), metadata.to(device)\n        optimizer.zero_grad()\n        outputs = model(images, metadata).squeeze(1)  # [batch_size]\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        \n        # Compute predictions for accuracy\n        preds = torch.sigmoid(outputs) > 0.5  # Apply sigmoid and threshold\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n    \n    train_loss = running_loss / len(loader)\n    train_accuracy = accuracy_score(all_labels, all_preds)\n    return train_loss, train_accuracy\n\n\ndef validate(model, loader, loss_fn, device):\n    model.eval()\n    running_loss = 0.0\n    all_preds, all_labels = [], []\n    \n    with torch.no_grad():\n        for images, labels, metadata in loader:\n            images, labels, metadata = images.to(device), labels.to(device), metadata.to(device)\n            outputs = model(images, metadata).squeeze(1)\n            loss = loss_fn(outputs, labels)\n            running_loss += loss.item()\n            \n            # Compute predictions for accuracy\n            preds = torch.sigmoid(outputs) > 0.5\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    \n    val_loss = running_loss / len(loader)\n    val_accuracy = accuracy_score(all_labels, all_preds)\n    return val_loss, val_accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:11:00.808530Z","iopub.execute_input":"2025-04-20T23:11:00.808810Z","iopub.status.idle":"2025-04-20T23:11:00.824320Z","shell.execute_reply.started":"2025-04-20T23:11:00.808794Z","shell.execute_reply":"2025-04-20T23:11:00.823581Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"# # Training loop\n# epochs = 20\n# train_losses = []\n# val_losses = []\n\n# for epoch in range(start_epoch, epochs):\n#     train_loss, train_accuracy = train_one_epoch(model, train_loader, loss_fn, optimizer, device)\n#     val_loss, val_accuracy = validate(model, val_loader, loss_fn, device)\n    \n#     train_losses.append(train_loss)\n#     val_losses.append(val_loss)\n#     train_accuracies.append(train_accuracy)\n#     val_accuracies.append(val_accuracy)\n    \n#     print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \" \n#           f\"Train Accuracy: {train_accuracy:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n\n#     scheduler.step(val_loss)\n    \n#     if val_loss < best_val_loss:\n#         best_val_loss = val_loss\n#         patience_counter = 0\n#         torch.save({\n#             \"model_state_dict\": model.state_dict(),\n#             \"optimizer_state_dict\": optimizer.state_dict(),\n#             \"epoch\": epoch,\n#             \"val_loss\": val_loss\n#         }, checkpoint_path)\n#         print(f\"Checkpoint saved at epoch {epoch+1}\")\n#     else:\n#         patience_counter += 1\n#         if patience_counter >= early_stopping_patience:\n#             print(\"Early stopping triggered\")\n#             break\n\n# plt.figure(figsize=(12, 5))\n# plt.plot(range(start_epoch+1, len(train_losses)+start_epoch+1), train_losses, label=\"Training Loss\")\n# plt.plot(range(start_epoch+1, len(val_losses)+start_epoch+1), val_losses, label=\"Validation Loss\")\n# plt.title(\"Loss over Epochs\")\n# plt.xlabel(\"Epochs\")\n# plt.ylabel(\"Loss\")\n# plt.legend()\n# plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:11:00.825110Z","iopub.execute_input":"2025-04-20T23:11:00.825355Z","iopub.status.idle":"2025-04-20T23:11:00.839606Z","shell.execute_reply.started":"2025-04-20T23:11:00.825332Z","shell.execute_reply":"2025-04-20T23:11:00.838965Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"# Point 2\n\n# Training loop\nepochs = 20\ntrain_losses, val_losses = [], []\ntrain_accuracies, val_accuracies = [], []  \n\nfor epoch in range(epochs):\n    train_loss, train_accuracy = train_one_epoch(model, train_loader, loss_fn, optimizer, device)\n    val_loss, val_accuracy = validate(model, val_loader, loss_fn, device)\n    \n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n    train_accuracies.append(train_accuracy)\n    val_accuracies.append(val_accuracy)\n    \n    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n          f\"Train Accuracy: {train_accuracy:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n    \n    scheduler.step(val_loss)\n    \n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        patience_counter = 0\n        torch.save({\n            \"model_state_dict\": model.state_dict(),\n            \"optimizer_state_dict\": optimizer.state_dict(),\n            \"epoch\": epoch,\n            \"val_loss\": val_loss\n        }, checkpoint_path)\n        print(f\"Checkpoint saved at epoch {epoch+1}\")\n    else:\n        patience_counter += 1\n        if patience_counter >= early_stopping_patience:\n            print(\"Early stopping triggered\")\n            break\n\n# Plot losses and accuracies\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(train_losses, label=\"Training Loss\")\nplt.plot(val_losses, label=\"Validation Loss\")\nplt.title(\"Loss over Epochs\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(train_accuracies, label=\"Training Accuracy\")\nplt.plot(val_accuracies, label=\"Validation Accuracy\")\nplt.title(\"Accuracy over Epochs\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\n\nplt.tight_layout()\nplt.show();","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T23:11:33.414846Z","iopub.execute_input":"2025-04-20T23:11:33.415175Z"}},"outputs":[{"name":"stderr","text":"  6%|▌         | 99/1657 [01:13<20:55,  1.24it/s] ","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# def save_predictions(model, loader, device, output_path=\"/kaggle/working/predictions.csv\"):\n#     model.eval()\n#     results = []\n#     with torch.no_grad():\n#         for images, labels, metadata in loader:\n#             images, labels, metadata = images.to(device), labels.to(device), metadata.to(device)\n#             outputs = torch.sigmoid(model(images, metadata).squeeze(1))\n#             preds = (outputs > 0.5).float()\n#             probs = outputs.cpu().numpy()\n#             for img_name, prob, pred, label in zip(loader.dataset.df[\"image_name\"], probs, preds, labels):\n#                 results.append({\"image_name\": img_name, \"probability\": prob, \"prediction\": pred.item(), \"true_label\": label.item()})\n    \n#     pd.DataFrame(results).to_csv(output_path, index=False)\n#     print(f\"Predictions saved to {output_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Evaluate and visualize\n# checkpoint = torch.load(checkpoint_path, map_location=device)\n# model.load_state_dict(checkpoint[\"model_state_dict\"])\n# evaluate(model, val_loader, device)\n# visualize_predictions(model, val_loader, device)\n# save_predictions(model, val_loader, device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_recall_fscore_support\nimport numpy as np\n\ndef evaluate(model, loader, device):\n    model.eval()\n    all_preds, all_labels = [], []\n    with torch.no_grad():\n        for images, labels, metadata in loader:\n            images, labels, metadata = images.to(device), labels.to(device), metadata.to(device)\n            outputs = torch.sigmoid(model(images, metadata).squeeze(1))  # Apply sigmoid for probabilities\n            preds = (outputs > 0.5).float()  # Threshold at 0.5\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    \n    accuracy = accuracy_score(all_labels, all_preds)\n    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"binary\")\n    print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n\n# Load best model and evaluate\ncheckpoint = torch.load(checkpoint_path)\nmodel.load_state_dict(checkpoint[\"model_state_dict\"])\nevaluate(model, val_loader, device)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-20T02:11:28.693Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualization","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\ndef visualize_predictions(model, loader, device, num_samples=5):\n    model.eval()\n    images, labels, metadata = next(iter(loader))\n    images, labels, metadata = images.to(device), labels.to(device), metadata.to(device)\n    with torch.no_grad():\n        outputs = torch.sigmoid(model(images, metadata).squeeze(1))\n        preds = (outputs > 0.5).float()\n    \n    for i in range(min(num_samples, len(images))):\n        plt.figure(figsize=(5, 5))\n        plt.imshow(images[i].cpu().permute(1, 2, 0).numpy())\n        plt.title(f\"True: {labels[i].item()}, Pred: {preds[i].item()}\")\n        plt.axis(\"off\")\n        plt.show()\n\n    # Confusion matrix\n    all_preds, all_labels = [], []\n    with torch.no_grad():\n        for images, labels, metadata in loader:\n            images, labels, metadata = images.to(device), labels.to(device), metadata.to(device)\n            outputs = torch.sigmoid(model(images, metadata).squeeze(1))\n            preds = (outputs > 0.5).float()\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    \n    cm = confusion_matrix(all_labels, all_preds)\n    plt.figure(figsize=(6, 6))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n    plt.title(\"Confusion Matrix\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    plt.show()\n\nvisualize_predictions(model, val_loader, device)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-20T02:11:28.697Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Saving Output","metadata":{}},{"cell_type":"code","source":"def save_predictions(model, loader, device, output_path=\"/kaggle/working/predictions.csv\"):\n    model.eval()\n    results = []\n    with torch.no_grad():\n        for images, labels, metadata in loader:\n            images, labels, metadata = images.to(device), labels.to(device), metadata.to(device)\n            outputs = torch.sigmoid(model(images, metadata).squeeze(1))\n            preds = (outputs > 0.5).float()\n            probs = outputs.cpu().numpy()\n            for img_name, prob, pred, label in zip(loader.dataset.df[\"image_name\"], probs, preds, labels):\n                results.append({\"image_name\": img_name, \"probability\": prob, \"prediction\": pred.item(), \"true_label\": label.item()})\n    \n    pd.DataFrame(results).to_csv(output_path, index=False)\n    print(f\"Predictions saved to {output_path}\")\n\nsave_predictions(model, val_loader, device)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-20T02:11:28.699Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv(os.path.join(data_dir, \"test.csv\"))\ntest_dataset = MedicalDataset(test_df, os.path.join(data_dir, \"jpeg/test\"), transform=val_transform)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\nresults = []\nmodel.eval()\nwith torch.no_grad():\n    for images, _, metadata in test_loader:\n        images, metadata = images.to(device), metadata.to(device)\n        outputs = torch.sigmoid(model(images, metadata).squeeze(1))\n        results.extend(outputs.cpu().numpy())\npd.DataFrame({\"image_name\": test_df[\"image_name\"], \"target\": results}).to_csv(\"/kaggle/working/submission.csv\", index=False)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-19T23:50:25.677Z"}},"outputs":[],"execution_count":null}]}